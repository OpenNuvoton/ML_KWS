{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6fbbded-bc97-4e62-b17e-6cdd86f567dc",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "# Import Section\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89a530a9-15b5-479f-b9e7-ee8ecf83b23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\miniforge3\\envs\\NuEdgeWise_env\\lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script provides functionality for cropping audio files. It includes the following imports:\n",
    "The script is intended to be run in a Jupyter notebook environment and uses interactive widgets to facilitate user interaction.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import math\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import read, write\n",
    "\n",
    "from ipywidgets import interact, interact_manual\n",
    "from IPython.display import clear_output\n",
    "from pydub import AudioSegment\n",
    "from ipyfilechooser import FileChooser\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import AppLayout, Button, Layout, HBox, GridBox\n",
    "import auditok\n",
    "\n",
    "from pydub import AudioSegment\n",
    "import pydub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee518ba-94a0-48a2-ab20-92472579e84c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Audio Process Section\n",
    "---\n",
    "- Show the audio wav file fugure\n",
    "- Processing the spliting wav file automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20a8c2c0-764c-429b-a5ca-7d17c4746c0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AudioFilep:  # father class\n",
    "    \"\"\"\n",
    "    A class to represent an audio file and perform operations related to it.\n",
    "    Attributes:\n",
    "    -----------\n",
    "    folder : str\n",
    "        The folder where the audio file is located.\n",
    "    filename : str\n",
    "        The name of the audio file.\n",
    "    filepath : str\n",
    "        The full path to the audio file.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, folder, filename):\n",
    "        self.folder = folder\n",
    "        self.filename = filename\n",
    "        self.filepath = os.path.join(folder, filename)\n",
    "\n",
    "    def create_tag_folder(self, tag_name):\n",
    "        \"\"\"\n",
    "        Creates a folder with the specified tag name in the current working directory.\n",
    "        If the folder already exists or an error occurs during creation, an error message is printed and folder creation is skipped.\n",
    "        \"\"\"\n",
    "        dir_path = os.path.join(os.getcwd(), tag_name)\n",
    "        try:\n",
    "            os.mkdir(dir_path)\n",
    "        except OSError as error:\n",
    "            print(error)\n",
    "            print(\"skip create\")\n",
    "\n",
    "        print(os.getcwd())\n",
    "\n",
    "\n",
    "class SplitWavAudionAutoV2(AudioFilep):\n",
    "    \"\"\"\n",
    "    A class to automatically slice audio files into smaller segments based on amplitude.\n",
    "    Attributes:\n",
    "    -----------\n",
    "        show_plots (bool): Flag to indicate whether to show plots of the slices.\n",
    "        rate (int): Sample rate of the audio file.\n",
    "        data (numpy.ndarray): Audio data.\n",
    "        tag (str): Path to the tag folder for saving slices.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, folder, filename, tagfolder, show_plots):\n",
    "        self.show_plots = show_plots\n",
    "        AudioFilep.__init__(self, folder, filename)\n",
    "        print(\"Auto slice V2\")\n",
    "        self.rate, self.data = read(self.filepath)\n",
    "        self.create_tag_folder(\"dataset\")\n",
    "        self.tag = os.path.join(\"dataset\", tagfolder)\n",
    "        self.create_tag_folder(self.tag)\n",
    "        print(f\"Sample rate: {self.rate} Hz\")\n",
    "        print(f\"Data type: {self.data.dtype}\")\n",
    "\n",
    "    def btach_process(self):\n",
    "        \"\"\"\n",
    "        Processes all files in the specified folder by performing the following steps:\n",
    "        \"\"\"\n",
    "        file_lists = os.listdir(self.folder)\n",
    "        for _, v in enumerate(file_lists):\n",
    "            self.filename = v\n",
    "            self.filepath = os.path.join(self.folder, self.filename)\n",
    "            print(self.filepath)\n",
    "            self.rate, self.data = read(self.filepath)\n",
    "            self.auto_slice(self.get_auto_slice_array())\n",
    "\n",
    "    def get_auto_slice_array(self):\n",
    "        \"\"\"\n",
    "        Calculate and return the start and end indices of slices in the audio data based on a sliding window approach.\n",
    "        The function uses a sliding window to calculate the sum of absolute values of the audio data within the window.\n",
    "        It then identifies slices where the sum exceeds a threshold (mean + standard deviation) and determines the\n",
    "        start and end indices of these slices.\n",
    "        Returns:\n",
    "            list of tuples: A list of tuples where each tuple contains the start and end indices of a slice.\n",
    "        \"\"\"\n",
    "        factor = 1  # control window size\n",
    "        win_size = self.rate  # training data's format, 1(s)\n",
    "        win_u = (int)((self.rate / 10) * factor)  # windows is 0.1(s) 16000/1600\n",
    "        s_r_factor = 0.5  # search range factor, too long may find the next slice part, too short may not find the real max val.\n",
    "\n",
    "        # create window's array for latter calculate #\n",
    "        sum_array = np.zeros((len(self.data) - win_u + 1), dtype=int)  # use 0.1(s) windows size to capture/calculate\n",
    "        data_abs = np.absolute(self.data)\n",
    "        for idx, _ in np.ndenumerate(sum_array):\n",
    "            sum_array[idx[0]] = np.sum(data_abs[idx[0] : (idx[0] + win_u)])\n",
    "\n",
    "        return self.__process_slice(sum_array, win_size, s_r_factor)\n",
    "\n",
    "    def __process_slice(self, sum_array, win_size, s_r_factor):\n",
    "\n",
    "        # define parameters #\n",
    "        mean_d_win = sum_array.mean()\n",
    "        std_win = sum_array.std()\n",
    "        temp_max = 0\n",
    "        temp_max_idx = 0\n",
    "        start = 0\n",
    "        end = 0\n",
    "        slice_idx = 0\n",
    "        slice_info = []\n",
    "\n",
    "        # find the slice's start&end idx and save all in slice_info array #\n",
    "        for idx, val in np.ndenumerate(sum_array):\n",
    "            if (val > mean_d_win + 1 * std_win) & (idx[0] > end):  # first time trig  # only check over the previous lat cut point\n",
    "\n",
    "                for i in range(idx[0], idx[0] + int(win_size * s_r_factor)):  # find the max window value in the range\n",
    "                    if i < len(sum_array) - 1:\n",
    "                        if temp_max < sum_array[i]:\n",
    "                            temp_max = sum_array[i]\n",
    "                            temp_max_idx = i\n",
    "\n",
    "                if (temp_max_idx - win_size / 2 + 1) < 0:  # decide the start & end slice indexs\n",
    "                    start = 0\n",
    "                    end = win_size - 1\n",
    "                elif (temp_max_idx + win_size / 2) > (len(self.data) - 1):\n",
    "                    start = len(self.data) - win_size\n",
    "                    end = len(self.data) - 1\n",
    "                else:\n",
    "                    start = (int)(temp_max_idx - win_size / 2 + 1)\n",
    "                    end = (int)(temp_max_idx + win_size / 2)\n",
    "\n",
    "                temp_max = 0\n",
    "                slice_idx = slice_idx + 1\n",
    "                slice_info.append((start, end))\n",
    "\n",
    "        return slice_info\n",
    "\n",
    "    def auto_slice(self, slice_a):\n",
    "        \"\"\"\n",
    "        Automatically slices the audio data and plots the slices.\n",
    "        Parameters:\n",
    "        slice_a (list of tuples): A list of tuples where each tuple contains the start and end indices of a slice.\n",
    "        This function performs the following steps:\n",
    "        1. Plots the entire audio data with slice boxes.\n",
    "        2. Saves each slice as a separate WAV file.\n",
    "        3. Optionally, plots each slice if `self.show_plots` is True.\n",
    "        The saved WAV files are named based on the original filename with an appended index.\n",
    "        \"\"\"\n",
    "\n",
    "        time = np.arange(0, len(self.data)) / self.rate\n",
    "        plt.figure(figsize=(20, 10))\n",
    "\n",
    "        plot_a = plt.subplot(211)\n",
    "        plot_a.plot(time, self.data)\n",
    "        plot_a.set_ylabel(\"Amplitude\")\n",
    "        plot_a.set_xlim(0, len(self.data) / self.rate)\n",
    "\n",
    "        # draw the slice boxes #\n",
    "        max_data = self.data.max()\n",
    "        for i, v in enumerate(slice_a):\n",
    "            if i % 2 == 1:\n",
    "                plot_a.vlines(v[0] / self.rate, -max_data - 5000, max_data + 5000, color=\"green\")\n",
    "                plot_a.vlines(v[1] / self.rate, -max_data - 5000, max_data + 5000, color=\"green\")\n",
    "                plot_a.hlines(-max_data - 5000, v[0] / self.rate, v[1] / self.rate, color=\"green\")\n",
    "                plot_a.hlines(max_data + 5000, v[0] / self.rate, v[1] / self.rate, color=\"green\")\n",
    "            else:\n",
    "                plot_a.vlines(v[0] / self.rate, -max_data - 5000, max_data + 5000, color=\"red\")\n",
    "                plot_a.vlines(v[1] / self.rate, -max_data - 5000, max_data + 5000, color=\"red\")\n",
    "                plot_a.hlines(-max_data - 5000, v[0] / self.rate, v[1] / self.rate, color=\"red\")\n",
    "                plot_a.hlines(max_data + 5000, v[0] / self.rate, v[1] / self.rate, color=\"red\")\n",
    "\n",
    "        self.__save_sliced_wav(slice_a)\n",
    "\n",
    "    def __save_sliced_wav(self, slice_a):\n",
    "        if self.show_plots:\n",
    "            plts_len = len(slice_a)\n",
    "            row = math.ceil(plts_len / 2)\n",
    "            col = 2\n",
    "\n",
    "            _, axs = plt.subplots(row, col, figsize=(15, 4 * row))\n",
    "\n",
    "        for i, v in enumerate(slice_a):  # draw the all single slice wav\n",
    "            if self.show_plots:\n",
    "                time = np.arange(v[0], v[1]) / self.rate\n",
    "                if row > 1:\n",
    "                    axs[i // 2, i % 2].plot(time, self.data[v[0] : v[1]])\n",
    "                    axs[i // 2, i % 2].set_ylabel(\"Amplitude\")\n",
    "                else:\n",
    "                    axs[i].plot(time, self.data[v[0] : v[1]])  # when 1 row, the axs is 1-D\n",
    "                    axs[i].set_ylabel(\"Amplitude\")\n",
    "\n",
    "            # save the slice data\n",
    "            name = self.filename.split(\"_nohash\")[0]\n",
    "            split_fn = name + \"_\" + str(i) + \"_nohash\"\n",
    "            file_loc = os.path.join(os.getcwd(), self.tag, split_fn)\n",
    "            if v[1] == len(self.data) - 1:\n",
    "                end_s = v[1]\n",
    "                start_s = v[0] - 1\n",
    "            else:\n",
    "                end_s = v[1] + 1\n",
    "                start_s = v[0]\n",
    "\n",
    "            write(f\"{file_loc}.wav\", self.rate, self.data[start_s:end_s])  # transfer from int32 to int16\n",
    "            print(f\"Region {i}: {(v[0]/self.rate):.3f}s -- {(v[1]/self.rate):.3f}s. Save as:{file_loc}\")\n",
    "\n",
    "\n",
    "class SplitWavAudionAuto(AudioFilep):\n",
    "    \"\"\"\n",
    "    A class to automatically split and process WAV audio files.\n",
    "    Attributes:\n",
    "    -----------\n",
    "    audio_reg : auditok.AudioRegion\n",
    "        The loaded audio region from the file.\n",
    "    tag : str\n",
    "        The folder where the tagged audio regions will be saved.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, folder, filename, tagfolder):\n",
    "        AudioFilep.__init__(self, folder, filename)\n",
    "        print(\"Can only process int16 file\")\n",
    "        self.audio_reg = auditok.load(self.filepath)\n",
    "        self.tag = tagfolder\n",
    "        self.create_tag_folder(tagfolder)\n",
    "\n",
    "    def draw(self):\n",
    "        \"\"\"\n",
    "        Draws a plot of the audio region.\n",
    "        \"\"\"\n",
    "        self.audio_reg.plot()\n",
    "\n",
    "    def auto_slice(self):\n",
    "        \"\"\"\n",
    "        Automatically slices the audio into regions based on specified parameters and saves each region as a separate file.\n",
    "        The function uses the `split_and_plot` method of the `audio_reg` object to divide the audio into regions.\n",
    "        Each region is then saved as a .wav file in the current working directory under a folder named after `self.tag`.\n",
    "        The function prints the start and end times of each region and the filename where the region is saved.\n",
    "        \"\"\"\n",
    "        audio_target = self.audio_reg.split_and_plot(\n",
    "            min_dur=0.1,\n",
    "            max_dur=3,\n",
    "            max_silence=0.5,\n",
    "            energy_threshold=45,\n",
    "            analysis_window=0.01,\n",
    "        )\n",
    "\n",
    "        for i, r in enumerate(audio_target):\n",
    "            print(\"Region {i}: {r.meta.start:.3f}s -- {r.meta.end:.3f}s\".format(i=i, r=r))\n",
    "\n",
    "            filename = r.save(os.path.join(os.getcwd(), self.tag, \"region_{meta.start:.3f}-{meta.end:.3f}.wav\"))\n",
    "            print(f\"Save as：{filename}\")\n",
    "\n",
    "\n",
    "class SplitWavAudioMubin(AudioFilep):\n",
    "    \"\"\"\n",
    "    A class to handle splitting of WAV audio files.\n",
    "    Attributes:\n",
    "    -----------\n",
    "    folder : str\n",
    "        The folder where the audio file is located.\n",
    "    filename : str\n",
    "        The name of the audio file.\n",
    "    tagfolder : str\n",
    "        The folder where the split audio files will be saved.\n",
    "    audio : AudioSegment\n",
    "        The loaded audio file.\n",
    "    tag : str\n",
    "        The tag folder name\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, folder, filename, tagfolder):\n",
    "        AudioFilep.__init__(self, folder, filename)\n",
    "        print(self.filepath)\n",
    "        self.audio = AudioSegment.from_wav(self.filepath)\n",
    "        self.tag = tagfolder\n",
    "        self.create_tag_folder(tagfolder)\n",
    "\n",
    "    def get_duration(self):\n",
    "        \"\"\"\n",
    "        Get the duration of the audio.\n",
    "        This method prints and returns the duration of the audio in seconds.\n",
    "        Returns:\n",
    "            float: The duration of the audio in seconds.\n",
    "        \"\"\"\n",
    "        print(self.audio.duration_seconds)\n",
    "        return self.audio.duration_seconds\n",
    "\n",
    "    def single_split(self, from_sec, to_sec, split_filename):\n",
    "        \"\"\"\n",
    "        Splits the audio file from a specified start time to end time and exports the split segment as a new file.\n",
    "        Args:\n",
    "            from_sec (int): The start time in seconds from which to begin the split.\n",
    "            to_sec (int): The end time in seconds at which to end the split.\n",
    "            split_filename (str): The name of the file to save the split audio segment.\n",
    "        \"\"\"\n",
    "        t1 = from_sec * 1000\n",
    "        t2 = to_sec * 1000\n",
    "        split_audio = self.audio[t1:t2]\n",
    "        file_loc = os.path.join(os.getcwd(), self.tag, split_filename)\n",
    "        split_audio.export(file_loc, format=\"wav\")\n",
    "\n",
    "    def multiple_split(self, sec_per_split, leap):\n",
    "        \"\"\"\n",
    "        Splits the audio file into multiple segments.\n",
    "\n",
    "        Args:\n",
    "            sec_per_split (int): The duration (in seconds) of each split segment.\n",
    "            leap (int): The number of seconds to skip between each split segment.\n",
    "        \"\"\"\n",
    "        total_secs = math.ceil(self.get_duration())\n",
    "        for i in range(0, total_secs, sec_per_split + leap):\n",
    "            split_fn = str(i) + \"_\" + self.filename\n",
    "            self.single_split(i, i + sec_per_split, split_fn)\n",
    "            print(str(i) + \" Done\")\n",
    "\n",
    "\n",
    "class DrawWav:\n",
    "    \"\"\"\n",
    "    A class to handle and visualize WAV audio files.\n",
    "    Attributes:\n",
    "    -----------\n",
    "    folder : str\n",
    "        The folder path where the WAV file is located.\n",
    "    filename : str\n",
    "        The name of the WAV file.\n",
    "    filepath : str\n",
    "        The full path to the WAV file.\n",
    "    rate : int\n",
    "        The sample rate of the WAV file.\n",
    "    data : numpy.ndarray\n",
    "        The audio data read from the WAV file.\n",
    "    ch : int\n",
    "        The number of channels in the audio data (1 for mono, 2 for stereo).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, folder, filename):\n",
    "        self.folder = folder\n",
    "        self.filename = filename\n",
    "        self.filepath = os.path.join(folder, filename)\n",
    "        self.rate, self.data = read(self.filepath)\n",
    "        self.ch = 1 if self.data.size / self.data.shape[0] == 1 else 2\n",
    "\n",
    "    def print_wavdata(self):\n",
    "        \"\"\"\n",
    "        Prints the details of the WAV data including sample rate, data type, duration in seconds,\n",
    "        number of channels, and data length.\n",
    "        \"\"\"\n",
    "        print(f\"Sample rate: {self.rate} Hz\")\n",
    "        print(f\"Data type: {self.data.dtype}\")\n",
    "        print(f\"Data Seconds: {self.data.shape[0] / self.rate} s\")\n",
    "        print(f\"Number of channels: {self.ch}\")\n",
    "        print(f\"Data length: {len(self.data)}\")\n",
    "\n",
    "    def stereo2mono(self):\n",
    "        \"\"\"\n",
    "        Converts stereo audio data to mono by averaging the two channels.\n",
    "        Returns:\n",
    "            numpy.ndarray: A 1D NumPy array containing the mono audio data.\n",
    "        \"\"\"\n",
    "        self.data = self.data.astype(float)\n",
    "        w_data = self.data.sum(axis=1) / 2\n",
    "        return w_data\n",
    "\n",
    "    def plot_wave(self):\n",
    "        \"\"\"\n",
    "        Plots the waveform and spectrogram of the audio data.\n",
    "        This method plots the time domain representation and the frequency domain\n",
    "        representation (spectrogram) of the audio data. If the audio data is stereo,\n",
    "        it will be converted to mono before plotting.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.ch == 2:\n",
    "            w_data = self.stereo2mono()\n",
    "        else:\n",
    "            w_data = self.data\n",
    "\n",
    "        # Time data\n",
    "        time = np.arange(0, len(w_data)) / self.rate\n",
    "        plt.figure(figsize=(15, 5))\n",
    "\n",
    "        # draw time domain\n",
    "        plot_a = plt.subplot(211)\n",
    "        plot_a.plot(time, w_data)\n",
    "        plot_a.set_ylabel(\"Amplitude\")\n",
    "        plot_a.set_xlim(0, len(w_data) / self.rate)\n",
    "\n",
    "        # draw frequency domain\n",
    "        plot_b = plt.subplot(212)\n",
    "        plot_b.specgram(w_data, NFFT=1024, Fs=self.rate, noverlap=900)\n",
    "        plot_b.set_ylabel(\"Frequency\")\n",
    "        plot_b.set_xlabel(\"Time\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "class SplitSingleWavAuto(AudioFilep):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, folder_path, fdir, file, window, min_silence_len, silence_thresh, pad_to_user_window): \n",
    "        self.folder_path = folder_path\n",
    "        self.folder = fdir\n",
    "        self.filename = file\n",
    "        self.autoslice_output_path = Path(os.getcwd()) / \"dataset\" / Path(self.folder)\n",
    "        self.window = window\n",
    "        self.min_silence_len = min_silence_len\n",
    "        self.silence_thresh = silence_thresh\n",
    "        self.pad_to_user_window = pad_to_user_window \n",
    "\n",
    "    def btach_process(self):\n",
    "        for wav_file in glob.glob(os.path.join(self.folder_path, \"*.wav\")):\n",
    "            print(wav_file)\n",
    "            win_idxs = self.get_single_slice_range(wav_file, self.min_silence_len, self.silence_thresh, self.window, self.autoslice_output_path)\n",
    "\n",
    "    def draw_single_slice_range(self, original_data, fr, slice_idx_list, file_name):\n",
    "        \"\"\"\n",
    "        Plots the waveform of the original data and overlays slice ranges as colored boxes.\n",
    "        Parameters:\n",
    "        -----------\n",
    "        original_data : numpy.ndarray\n",
    "            The audio data to be plotted.\n",
    "        fr : int or float\n",
    "            The sampling frequency of the audio data.\n",
    "        slice_idx_list : list of tuples\n",
    "            A list of slice index ranges, where each tuple contains two integers \n",
    "            representing the start and end indices of a slice. Alternating slices \n",
    "            are colored green and red.\n",
    "        file_name : str\n",
    "            The title of the plot, typically the name of the file being visualized.\n",
    "        \"\"\"\n",
    "        time = np.arange(0, len(original_data)) / fr  # Create a time array\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        plot_a = plt.subplot(211)\n",
    "        plot_a.plot(time, original_data)\n",
    "        plot_a.set_ylabel(\"Amplitude\")\n",
    "        plot_a.set_xlim(0, len(original_data) / fr)\n",
    "        plot_a.set_title(str(file_name))\n",
    "        # draw the slice boxes #\n",
    "        max_data = original_data.max()\n",
    "    \n",
    "        for i, v in enumerate(slice_idx_list):\n",
    "            if i % 2 == 1:\n",
    "                plot_a.vlines(v[0] / 1000, -max_data - 5000, max_data + 5000, color=\"green\")\n",
    "                plot_a.vlines(v[1] / 1000, -max_data - 5000, max_data + 5000, color=\"green\")\n",
    "                plot_a.hlines(-max_data - 5000, v[0] / 1000, v[1] / 1000, color=\"green\")\n",
    "                plot_a.hlines(max_data + 5000, v[0] / 1000, v[1] / 1000, color=\"green\")\n",
    "            else:\n",
    "                plot_a.vlines(v[0] / 1000, -max_data - 5000, max_data + 5000, color=\"red\")\n",
    "                plot_a.vlines(v[1] / 1000, -max_data - 5000, max_data + 5000, color=\"red\")\n",
    "                plot_a.hlines(-max_data - 5000, v[0] / 1000, v[1] / 1000, color=\"red\")\n",
    "                plot_a.hlines(max_data + 5000, v[0] / 1000, v[1] / 1000, color=\"red\")\n",
    "    \n",
    "    \n",
    "    def save_single_slice_range(self, ori_audio, slice_idx_list, sliced_audio_path):\n",
    "        \"\"\"\n",
    "        Save a specific range of an audio file as a new audio file.\n",
    "        This function takes an original audio object, extracts a specific slice\n",
    "        of the audio based on the provided index range, and saves the sliced\n",
    "        audio to the specified file path in WAV format.\n",
    "        Args:\n",
    "            ori_audio: An audio object representing the original audio data.\n",
    "            slice_idx_list (list of tuples): A list containing tuples where each\n",
    "                tuple specifies the start and end indices of the slice to extract.\n",
    "                Only the first tuple in the list is used.\n",
    "            sliced_audio_path (str): The file path where the sliced audio will be\n",
    "                saved in WAV format.\n",
    "        \"\"\"\n",
    "        ori_audio = ori_audio[slice_idx_list[0][0]:slice_idx_list[0][1]]\n",
    "    \n",
    "        ori_audio.export(sliced_audio_path, format=\"wav\")\n",
    "    \n",
    "    \n",
    "    def get_single_slice_range(self, audio_path, min_silence_len, silence_thresh, user_set_window, output_save_path, pad_to_user_window=True):\n",
    "        \"\"\"\n",
    "        Get the single slice range of the audio file.\n",
    "        \"\"\"\n",
    "        # Create the output directory if it doesn't exist\n",
    "        output_save_path.mkdir(exist_ok=True)\n",
    "    \n",
    "        # Load the audio file\n",
    "        audio_segment = AudioSegment.from_file(audio_path, format=\"wav\")\n",
    "        channel_count = audio_segment.channels\n",
    "        if channel_count > 1:\n",
    "            audio_segment = audio_segment.set_channels(1)  # Convert to mono\n",
    "        frames_per_second = audio_segment.frame_rate\n",
    "        if frames_per_second != 16000:\n",
    "            audio_segment = audio_segment.set_frame_rate(16000)\n",
    "        sample_width = audio_segment.sample_width\n",
    "        if sample_width != 2:\n",
    "            audio_segment = audio_segment.set_sample_width(2)  # Convert to 16-bit\n",
    "        print(f\"channel_num: {channel_count}, frame_rate: {frames_per_second}, length: {(len(audio_segment) / 1000.0)}, sample_width: {sample_width}\")\n",
    "    \n",
    "        # assert len(audio_segment) >= user_set_window, f\"user set window should be smaller than the size of wav file.\"\n",
    "        if len(audio_segment) > user_set_window:\n",
    "    \n",
    "            not_silence_ranges = pydub.silence.detect_nonsilent(audio_segment, min_silence_len=min_silence_len, silence_thresh=silence_thresh, seek_step=1)\n",
    "            print(f\"original slice range (ms): {not_silence_ranges}\")\n",
    "    \n",
    "            # Combine the ranges list's first value with the last value\n",
    "            single_slice_range = []\n",
    "            if len(not_silence_ranges) > 1:\n",
    "                single_slice_range = (not_silence_ranges[0][0], not_silence_ranges[-1][1])\n",
    "            elif len(not_silence_ranges) == 1:\n",
    "                single_slice_range = not_silence_ranges[0]\n",
    "            else:\n",
    "                print(\"No slice range found\")\n",
    "    \n",
    "            # update the not_silence_ranges to be more accurate & basing on user setting\n",
    "            slice_window = single_slice_range[1] - single_slice_range[0]\n",
    "            if slice_window > user_set_window:\n",
    "                # if the slice window is too long, we need to split it into two, first from begin, second from end\n",
    "                not_silence_ranges = [(single_slice_range[0], single_slice_range[0] + user_set_window), (single_slice_range[1] - user_set_window, single_slice_range[1])]\n",
    "                not_silence_ranges = [not_silence_ranges[0]]\n",
    "            else:\n",
    "                # if the slice window is too short, we need to pad it before&after\n",
    "                pad_size = np.ceil((user_set_window - slice_window) / 2)\n",
    "                pad_idx_begin = 0\n",
    "                pad_idx_end = 0\n",
    "    \n",
    "                # pad before\n",
    "                if single_slice_range[0] - pad_size > 0:\n",
    "                    pad_idx_begin = single_slice_range[0] - pad_size\n",
    "                else:\n",
    "                    pad_idx_begin = 0\n",
    "                    # update the pad size\n",
    "                    pad_size = (user_set_window - slice_window) - single_slice_range[0]\n",
    "    \n",
    "                # pad after\n",
    "                if single_slice_range[1] + pad_size < len(audio_segment):\n",
    "                    pad_idx_end = single_slice_range[1] + pad_size\n",
    "                else:\n",
    "                    pad_idx_end = len(audio_segment)\n",
    "                    # update the begin index\n",
    "                    pad_size = (user_set_window - slice_window) - (len(audio_segment) - single_slice_range[1])\n",
    "                    pad_idx_begin = single_slice_range[0] - pad_size\n",
    "                # update the not_silence_ranges\n",
    "                not_silence_ranges = [(pad_idx_begin, pad_idx_end)]\n",
    "    \n",
    "            print(f\"updated slice range (ms): {not_silence_ranges}\")\n",
    "            self.draw_single_slice_range(np.array(audio_segment.get_array_of_samples()), frames_per_second, not_silence_ranges, Path(audio_path).name)\n",
    "            sliced_audio_path = os.path.join(output_save_path, (Path(audio_path).stem + \"_\" + str(user_set_window / 1000) + \"s\" + \"_\" + \"0\" + \"_nohash\" + Path(audio_path).suffix))\n",
    "            self.save_single_slice_range(audio_segment, not_silence_ranges, sliced_audio_path)\n",
    "        else:\n",
    "            if pad_to_user_window:\n",
    "                padding_needed = np.ceil((user_set_window - len(audio_segment)) / 2)\n",
    "                silence = AudioSegment.silent(duration=padding_needed)\n",
    "                # Add silence to the end of the audio\n",
    "                padded_audio = silence + audio_segment + silence\n",
    "                not_silence_ranges = [(0, len(padded_audio))]\n",
    "    \n",
    "                print(f\"audio length is shorter than user set window, padding!! updated slice range (ms): {not_silence_ranges}\")\n",
    "                self.draw_single_slice_range(np.array(padded_audio.get_array_of_samples()), frames_per_second, not_silence_ranges, Path(audio_path).name)\n",
    "                sliced_audio_path = os.path.join(output_save_path, (Path(audio_path).stem + \"_\" + str(user_set_window / 1000) + \"s\" + \"_\" + \"0\" + \"_nohash\" + Path(audio_path).suffix))\n",
    "                self.save_single_slice_range(padded_audio, not_silence_ranges, sliced_audio_path)\n",
    "            else:\n",
    "                print(f\"audio length is shorter than user set window, {audio_path} SKIP!\")\n",
    "                not_silence_ranges = None\n",
    "    \n",
    "        return not_silence_ranges               "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c5f6cf-51e1-4367-9dbe-124796de087f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Widgets Control Section\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9b586f3-6121-4754-be6a-09d334869c76",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = widgets.Output()  # interact output\n",
    "\n",
    "\n",
    "class InitAudio:\n",
    "    \"\"\"\n",
    "    A class to initialize and interact with audio files in a directory.\n",
    "\n",
    "    Attributes:\n",
    "    -----------\n",
    "    mypath : str\n",
    "        The current working directory path.\n",
    "    dirpath : str\n",
    "        The directory path of the first level.\n",
    "    dirnames : list\n",
    "        The list of directory names in the first level.\n",
    "    filenames : list\n",
    "        The list of filenames in the first level.\n",
    "\n",
    "    Methods:\n",
    "    --------\n",
    "    get_firstlevel():\n",
    "        Retrieves the first level of directories and files.\n",
    "\n",
    "    create_expanded_button(description, button_style):\n",
    "        Creates an expanded button with the given description and style.\n",
    "\n",
    "    copy_allfiles(src_folder, dst_folder):\n",
    "        Copies all files from the source folder to the destination folder.\n",
    "\n",
    "    interact_block_audio():\n",
    "        Creates an interactive block for audio file selection and processing.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.mypath = os.getcwd()\n",
    "        self.dirpath, self.dirnames, self.filenames = self.get_firstlevel()\n",
    "        self.file = None\n",
    "        self.folder_loc = None\n",
    "        self.fdir = None\n",
    "\n",
    "    def get_firstlevel(self):  # get a list of folders\n",
    "        \"\"\"\n",
    "        Retrieves the first level of directories and files in the specified path.\n",
    "        Returns:\n",
    "            tuple: A tuple containing:\n",
    "                - dirpath (str): The path to the directory.\n",
    "                - dirnames (list): A list of directory names in the first level.\n",
    "                - filenames (list): A list of file names in the first level.\n",
    "        \"\"\"\n",
    "        dirpath, dirnames, filenames = next(os.walk(self.mypath))\n",
    "\n",
    "        return dirpath, dirnames, filenames\n",
    "\n",
    "    def create_expanded_button(self, description, button_style):\n",
    "        \"\"\"\n",
    "        Create a Button widget with the specified description and style.\n",
    "        Parameters:\n",
    "        description (str): The text to display on the button.\n",
    "        button_style (str): The style of the button (e.g., 'primary', 'success', 'info', 'warning', 'danger').\n",
    "        Returns:\n",
    "        Button: A Button widget with the specified description and style.\n",
    "        \"\"\"\n",
    "        return Button(\n",
    "            disabled=False,\n",
    "            description=description,\n",
    "            button_style=button_style,\n",
    "            layout=Layout(height=\"auto\", width=\"auto\"),\n",
    "        )\n",
    "\n",
    "    def copy_allfiles(self, src_folder, dst_folder):\n",
    "        \"\"\"\n",
    "        Copies all files from the source folder to the destination folder.\n",
    "        Args:\n",
    "            src_folder (str): The path to the source folder.\n",
    "            dst_folder (str): The path to the destination folder.\n",
    "        \"\"\"\n",
    "        copy_num = 0\n",
    "        for file_name in os.listdir(src_folder):\n",
    "            source = os.path.join(src_folder, file_name)\n",
    "            destination = os.path.join(dst_folder, file_name)\n",
    "            # copy only files\n",
    "            if os.path.isfile(source):\n",
    "                shutil.copy(source, destination)\n",
    "                copy_num = copy_num + 1\n",
    "        print(f\"Copy finish, total {copy_num} files\")\n",
    "\n",
    "    def on_button_clicked_event_a(self, b):\n",
    "        \"\"\"\n",
    "        Event handler for button click event 'a'.\n",
    "        \"\"\"\n",
    "        with output:\n",
    "            clear_output()\n",
    "            draw_wav = DrawWav(self.folder_loc, self.file)\n",
    "            draw_wav.print_wavdata()\n",
    "            draw_wav.plot_wave()\n",
    "\n",
    "    def on_button_clicked_event_b(self, b):\n",
    "        \"\"\"\n",
    "        Event handler for button click event.\n",
    "        This function is triggered when a button is clicked. It clears the current output,\n",
    "        prints a message to prompt the user to set the slice parameters, and then creates\n",
    "        an interactive widget for splitting a WAV file.\n",
    "        \"\"\"\n",
    "        with output:\n",
    "            clear_output()\n",
    "            print(\"Please set the slice!!\")\n",
    "\n",
    "            def act_split_wav(sec_per_split, leap, tag_name):\n",
    "                split_wav = SplitWavAudioMubin(self.folder_loc, self.file, tag_name)\n",
    "                split_wav.multiple_split(sec_per_split, leap)\n",
    "                return (sec_per_split, leap, tag_name)\n",
    "\n",
    "            evt = interact_manual(\n",
    "                act_split_wav,\n",
    "                sec_per_split=widgets.IntSlider(min=0, max=10, step=1, value=10, description=\"Seconds/Slice\"),\n",
    "                leap=widgets.IntSlider(min=0, max=10, step=1, value=1, description=\"Gap\"),\n",
    "                tag_name=widgets.Text(value=\"test_slice\", description=\"Label\"),\n",
    "            )\n",
    "            evt.widget.children[3].description = \"Start Slice\"  # because there are 3 parameter of the evt\n",
    "            evt.widget.children[3].button_style = \"success\"\n",
    "\n",
    "    def on_button_clicked_event_c(self, b):\n",
    "        \"\"\"\n",
    "        Event handler for button click event.\n",
    "        This function is triggered when a button is clicked. It clears the current output and\n",
    "        sets up an interactive manual widget to perform automatic audio slicing.\n",
    "        \"\"\"\n",
    "        with output:\n",
    "            clear_output()\n",
    "\n",
    "            def act_auto_split(tag_name, batch_en, show_plots):\n",
    "                if not batch_en:\n",
    "                    split_auto_v2 = SplitWavAudionAutoV2(self.folder_loc, self.file, tag_name, show_plots)\n",
    "                    split_auto_v2.auto_slice(split_auto_v2.get_auto_slice_array())\n",
    "                else:\n",
    "                    print(\"auto slice batch\")\n",
    "                    split_auto_v2 = SplitWavAudionAutoV2(self.folder_loc, self.file, tag_name, show_plots)\n",
    "                    split_auto_v2.btach_process()\n",
    "\n",
    "            evt = interact_manual(\n",
    "                act_auto_split,\n",
    "                tag_name=widgets.Text(value=\"test_slice\", description=\"Label\"),\n",
    "                batch_en=widgets.Checkbox(\n",
    "                    value=True,\n",
    "                    disabled=False,\n",
    "                    indent=False,\n",
    "                    description=\"Batch Enable\",\n",
    "                ),\n",
    "                show_plots=widgets.Checkbox(\n",
    "                    value=False,\n",
    "                    disabled=False,\n",
    "                    indent=False,\n",
    "                    description=\"Show Plots\",\n",
    "                ),\n",
    "            )\n",
    "            evt.widget.children[3].description = \"Start Slice\"  # because there are 3 parameter of the evt\n",
    "            evt.widget.children[3].button_style = \"success\"\n",
    "\n",
    "    def on_button_clicked_event_d(self, b):\n",
    "        \"\"\"\n",
    "        Handles the event when a button is clicked.\n",
    "        \"\"\"\n",
    "        with output:\n",
    "            clear_output()\n",
    "            path_fc = os.path.abspath(\"dataset\")  # The processed data are in /dataset\n",
    "            fc = FileChooser(path_fc)\n",
    "            fc.show_only_dirs = True\n",
    "            fc.title = \"<b><font color='lightgreen'><font size=4>Choose train label folder.</b>\"\n",
    "            display(fc)\n",
    "            path_f_copy = os.path.abspath(\"..\")  # The train program is in ../ML_kws_tflu\n",
    "            path_f_copy = os.path.join(path_f_copy, \"ML_kws_tflu\", \"tmp\", \"speech_dataset\")\n",
    "\n",
    "            def act_copy_folder():\n",
    "                print(f\"Selected folder: {fc.selected_path}\")\n",
    "                copied_folder_name = Path(fc.selected_path).parts[-1]\n",
    "                copied_dst = os.path.join(path_f_copy, copied_folder_name)\n",
    "                if not os.path.isdir(copied_dst):  # check if the folder exists or not, if not creat it.\n",
    "                    os.makedirs(copied_dst)\n",
    "                print(f\"Copy to: {path_f_copy}\")\n",
    "                self.copy_allfiles(fc.selected_path, copied_dst)\n",
    "\n",
    "            evt = interact_manual(act_copy_folder)\n",
    "            evt.widget.children[0].description = \"Start Copy\"  # because there are 3 parameter of the evt\n",
    "            evt.widget.children[0].button_style = \"success\"\n",
    "\n",
    "    def on_button_clicked_event_e(self, b):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        with output:\n",
    "            clear_output()\n",
    "\n",
    "            def act_auto_single_split(window, min_silence_len, silence_thresh, pad_to_user_window):\n",
    "                \n",
    "                print(\"auto single slice batch\")\n",
    "                split_single_auto = SplitSingleWavAuto(self.folder_loc, self.fdir, self.file, window, min_silence_len, silence_thresh, pad_to_user_window)\n",
    "                split_single_auto.btach_process()\n",
    "\n",
    "            evt = interact_manual(\n",
    "                act_auto_single_split,\n",
    "                window = widgets.BoundedIntText(min=500, max=6000, step=500, value=1000, description=\"USER SET WINDOW\", \n",
    "                                                style={'description_width': '200px'}, layout=widgets.Layout(width='300px')),\n",
    "                min_silence_len = widgets.BoundedIntText(min=100, max=6000, step=100, value=300, description=\"MIN SILENCE LEN\", \n",
    "                                                         style={'description_width': '200px'}, layout=widgets.Layout(width='300px')),\n",
    "                silence_thresh = widgets.IntText(value=-35, description=\"SILENCE THRESH\", \n",
    "                                                 style={'description_width': '200px'}, layout=widgets.Layout(width='300px')),\n",
    "                pad_to_user_window = widgets.Checkbox(value=True,description='PAD TO USER WINDOW', \n",
    "                                                    ),\n",
    "                layout=Layout(width='100%', height='80px')\n",
    "                )\n",
    "            evt.widget.children[4].description = \"Start Slice\"  # because there are 3 parameter of the evt\n",
    "            evt.widget.children[4].button_style = \"success\"        \n",
    "\n",
    "    def interact_block_audio(self):\n",
    "        \"\"\"\n",
    "        Creates an interactive widget-based interface for selecting and processing audio files.\n",
    "        This method provides a graphical interface using Jupyter widgets to:\n",
    "        - Select a folder and file from the directory.\n",
    "        - Display buttons for various audio processing tasks:\n",
    "            - Run Wav Plot: Plots the waveform of the selected audio file.\n",
    "            - Slice Wav: Manually slices the audio file based on user-defined parameters.\n",
    "            - Slice Wav Auto: Automatically slices the audio file with optional batch processing and plotting.\n",
    "            - Copy to where (for training use): Copies the processed audio files to a specified training directory.\n",
    "        The interface dynamically updates the available files based on the selected folder and provides\n",
    "        interactive controls for each processing task.\n",
    "        \"\"\"\n",
    "\n",
    "        dirnames = self.dirnames\n",
    "        choose_folder = widgets.Dropdown(options=dirnames)\n",
    "        choose_file = widgets.Dropdown(options=os.listdir(choose_folder.value))\n",
    "\n",
    "        def update_choose_file(*args):  # Updates the choose_file options based on choose_folder value\n",
    "            choose_file.options = os.listdir(choose_folder.value)\n",
    "\n",
    "        choose_folder.observe(update_choose_file, \"value\")  # Tie the choose_file options to choose_folder value\n",
    "\n",
    "        def show_workarea(fdir, file):\n",
    "            self.file = file\n",
    "            self.folder_loc = os.path.join(os.getcwd(), fdir)\n",
    "            self.fdir = fdir\n",
    "            print(f\"Choosed folder: {self.folder_loc}\")\n",
    "            print(f\"Choosed file: {self.file}\")\n",
    "\n",
    "            button_a = self.create_expanded_button(\"Run Wav Plot\", \"success\")\n",
    "            button_b = self.create_expanded_button(\"Slice Wav\", \"info\")\n",
    "            button_c = self.create_expanded_button(\"Slice Wav Auto\", \"warning\")\n",
    "            button_d = self.create_expanded_button(\"Copy to where(for training use)\", \"info\")\n",
    "            button_e = self.create_expanded_button(\"Slice Single Wav Auto\", \"warning\")\n",
    "\n",
    "            display(  # show the buttom and output\n",
    "                AppLayout(\n",
    "                    header=button_e,\n",
    "                    left_sidebar=button_a,\n",
    "                    center=button_b,\n",
    "                    right_sidebar=button_c,\n",
    "                    footer=button_d,\n",
    "                    pane_widths=[3, 3, 3],\n",
    "                    pane_heights=[\"40px\", \"40px\", \"40px\"],\n",
    "                ),\n",
    "                output,\n",
    "            )\n",
    "\n",
    "            button_a.on_click(self.on_button_clicked_event_a)\n",
    "\n",
    "            button_b.on_click(self.on_button_clicked_event_b)\n",
    "\n",
    "            button_c.on_click(self.on_button_clicked_event_c)\n",
    "\n",
    "            button_d.on_click(self.on_button_clicked_event_d)\n",
    "\n",
    "            button_e.on_click(self.on_button_clicked_event_e)\n",
    "\n",
    "        if choose_folder.value is not None:\n",
    "            _ = interact(show_workarea, fdir=choose_folder, file=choose_file)\n",
    "        else:\n",
    "            print(f\"Please at least a folder in {os.getcwd()}!!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62f367b-df45-4948-9b55-68114076b602",
   "metadata": {},
   "source": [
    "# Run Section\n",
    "- The detail description is here [meaning](#id-control-intro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06ef0918-76ed-4f05-bc42-b70ba331a255",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3d00e15c7f4a16b8512dfcca7fcf98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='fdir', options=('.ipynb_checkpoints', 'dataset', 'raw1', '功能词-唤醒30…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "audio_proj = InitAudio()\n",
    "audio_proj.interact_block_audio()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffbaec6-9ddb-481f-b4c6-53d4dbcc61a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"id-control-intro\"></a>\n",
    "# Control Introduction\n",
    "---\n",
    "\n",
    "- `fdir`: the folders in `ML_audio_aq` folder, you can choose any one of them.\n",
    "- `file`: the files in the choosen folder, you can choose any one of them.\n",
    "- `Run Wav Plot`: show the *.wav's figure.\n",
    "- `Slice Wav`: manually slice the single wav file(old).\n",
    "- `Slice Wav Auto`: smartly slice the single or whole folder's wav files.\n",
    "\n",
    "- In `Slice Wav Auto`:\n",
    "    1. Label is the folder's name which save all the sliced wav files. You should follow the training's label(answer).\n",
    "    2. `Btach Enable`: slice the whole folder's wav files.\n",
    "    3. `Show Plots`: show each sliced small plots.\n",
    "    4. `Start Slice`: you can click this buttom after all setting is done.\n",
    "    5. (recommend)(will update) The output `Label` folder is saved in `dataset`. You can copy/move the folders to training step's train_data_folder, for example: in `ML_kws_tflu\\tmp\\speech_dataset`\n",
    "\n",
    "---\n",
    "- In `Slice Single Wav Auto`:\n",
    "    - `FOLDER_PATH`: 欲切割之目標資料夾. 切割後的資料夾在 `dataset\\{user set folder_path}`\n",
    "    - `USER_SET_WINDOW`: 欲設定之固定窗口大小.\n",
    "    - `MIN_SILENCE_LEN`: 持续多少时间可认定为静默\n",
    "    - `SILENCE_THRESH`: 声音大小小于多少时可认定为静默，默认值为-16dBFS\n",
    "    - `PAD_TO_USER_WINDOW`: True or False. 如果欲切割wav檔長度小於設定之固定窗口大小，決定是否在原檔前後padding\n",
    "    - 建議: 如果自動分割效果不太好，再自行調整`min_silence_len`和`silence_thresh`    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496d64d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NuEdgeWise_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
