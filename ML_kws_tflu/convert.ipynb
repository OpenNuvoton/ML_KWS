{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ff97548",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import Section\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8c00fe7",
   "metadata": {
    "id": "e8c00fe7",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script is used for converting and testing TensorFlow Lite models for keyword spotting (KWS).\n",
    "\"\"\"\n",
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "import shutil\n",
    "from collections import OrderedDict\n",
    "\n",
    "import tensorflow as tf\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout, Box, Dropdown, Label\n",
    "from IPython.display import display, HTML\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from kws_python import data\n",
    "from kws_python import models\n",
    "from kws_python.test_tflite import tflite_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tMWTmtEEtRy-",
   "metadata": {
    "id": "tMWTmtEEtRy-",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Location:\n",
      "c:\\CYCHEN38\\OpenNuvoton\\ML_KWS\\ML_kws_tflu\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # For using colab\n",
    "    from google.colab import drive\n",
    "\n",
    "    print(\"origin is:\")\n",
    "    print(os.getcwd())\n",
    "    drive.mount(\"/content/drive\")\n",
    "\n",
    "    os.chdir(r\"/content/drive/MyDrive/tflu-kws-cortex-m/Training\")\n",
    "    print(\"update to:\")\n",
    "    print(os.getcwd())\n",
    "\n",
    "except ImportError:\n",
    "    print(r\"Running Location:\")\n",
    "    print(os.path.abspath(os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc7f406",
   "metadata": {
    "id": "fcc7f406",
    "tags": []
   },
   "source": [
    "# Convert Section\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86add9a7",
   "metadata": {
    "id": "86add9a7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_REP_DATA_SAMPLES = 100  # How many samples to use for post training quantization.\n",
    "\n",
    "\n",
    "def convert(*, flags, model_settings, audio_processor, checkpoint, quantize, inference_type, tflite_path):\n",
    "    \"\"\"Load our trained floating point model and convert it.\n",
    "\n",
    "    TFLite conversion or post training quantization is performed and the\n",
    "    resulting model is saved as a TFLite file.\n",
    "    We use samples from the validation set to do post training quantization.\n",
    "\n",
    "    Args:\n",
    "        model_settings: Dictionary of common model settings.\n",
    "        audio_processor: Audio processor class object.\n",
    "        checkpoint: Path to training checkpoint to load.\n",
    "        quantize: Whether to quantize the model or convert to fp32 TFLite model.\n",
    "        inference_type: Input/output type of the quantized model.\n",
    "        tflite_path: Output TFLite file save path.\n",
    "    \"\"\"\n",
    "    model = models.create_model(model_settings, flags.model_architecture, flags.model_size_info, False)\n",
    "    model.load_weights(checkpoint).expect_partial()\n",
    "\n",
    "    val_data = audio_processor.get_data(audio_processor.Modes.VALIDATION).batch(1)\n",
    "\n",
    "    def _rep_dataset():\n",
    "        \"\"\"Generator function to produce representative dataset.\"\"\"\n",
    "        i = 0\n",
    "        for mfcc, _ in val_data:\n",
    "            if i > NUM_REP_DATA_SAMPLES:\n",
    "                break\n",
    "            i += 1\n",
    "            yield [mfcc]\n",
    "\n",
    "    if quantize:\n",
    "        # Quantize model and save to disk.\n",
    "        tflite_model = post_training_quantize(model, inference_type, _rep_dataset)\n",
    "        with open(tflite_path, \"wb\") as f:\n",
    "            f.write(tflite_model)\n",
    "        print(f\"Quantized model saved to {tflite_path}.\")\n",
    "    else:\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        tflite_model = converter.convert()\n",
    "        with open(tflite_path, \"wb\") as f:\n",
    "            f.write(tflite_model)\n",
    "        print(f\"Converted model saved to {tflite_path}.\")\n",
    "\n",
    "\n",
    "def post_training_quantize(keras_model, inference_type, rep_dataset):\n",
    "    \"\"\"Perform post training quantization and returns the TFLite model ready for saving.\n",
    "\n",
    "    See https://www.tensorflow.org/lite/performance/post_training_quantization#full_integer_quantization for\n",
    "    more details.\n",
    "\n",
    "    Args:\n",
    "        keras_model: The trained tf Keras model used for post training quantization.\n",
    "        inference_type: Input/output type of the quantized model.\n",
    "        rep_dataset: Function to use as a representative dataset, must be callable.\n",
    "\n",
    "    Returns:\n",
    "        Quantized TFLite model ready for saving to disk.\n",
    "    \"\"\"\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "    if inference_type == \"int8\":\n",
    "        converter.inference_input_type = tf.int8\n",
    "        converter.inference_output_type = tf.int8\n",
    "\n",
    "    # Int8 post training quantization needs representative dataset.\n",
    "    converter.representative_dataset = rep_dataset\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    return tflite_model\n",
    "\n",
    "\n",
    "def main_convert(flags):\n",
    "    \"\"\"\n",
    "    Converts a trained model to TensorFlow Lite format and tests it.\n",
    "    Returns:\n",
    "        str: Path to the converted TensorFlow Lite model file.\n",
    "    \"\"\"\n",
    "    model_settings = models.prepare_model_settings(\n",
    "        len(data.prepare_words_list(flags.wanted_words.split(\",\"))), flags.sample_rate, flags.clip_duration_ms, flags.window_size_ms, flags.window_stride_ms, flags.dct_coefficient_count\n",
    "    )\n",
    "\n",
    "    audio_processor = data.AudioProcessor(\n",
    "        data_exist=flags.data_exist,\n",
    "        data_url=flags.data_url,\n",
    "        data_dir=flags.data_dir,\n",
    "        silence_percentage=flags.silence_percentage,\n",
    "        unknown_percentage=flags.unknown_percentage,\n",
    "        wanted_words=flags.wanted_words.split(\",\"),\n",
    "        validation_percentage=flags.validation_percentage,\n",
    "        testing_percentage=flags.testing_percentage,\n",
    "        model_settings=model_settings,\n",
    "    )\n",
    "\n",
    "    if flags.quantize:\n",
    "        if flags.inference_type == \"int8\":\n",
    "            tflite_path = f\"{flags.model_architecture}_int8quant.tflite\"\n",
    "        else:\n",
    "            tflite_path = f\"{flags.model_architecture}_dyquant.tflite\"\n",
    "    else:\n",
    "        tflite_path = f\"{flags.model_architecture}.tflite\"\n",
    "\n",
    "    tflite_path = os.path.join(flags.checkpoint.split(\"best\")[0], tflite_path)\n",
    "\n",
    "    # Load floating point model from checkpoint and convert it.\n",
    "    convert(\n",
    "        flags=flags, model_settings=model_settings, audio_processor=audio_processor, checkpoint=flags.checkpoint, quantize=flags.quantize, inference_type=flags.inference_type, tflite_path=tflite_path\n",
    "    )\n",
    "\n",
    "    # Test the newly converted model on the test set.\n",
    "    tflite_test(model_settings, audio_processor, tflite_path)\n",
    "\n",
    "    return tflite_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e8c7a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Argument Setting\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d510d6ed",
   "metadata": {
    "id": "d510d6ed",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data_exist\", type=bool, default=True, help=\"True will skip download and tar.\")\n",
    "    parser.add_argument(\"--data_url\", type=str, default=\"http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz\", help=\"Location of speech training data archive on the web.\")\n",
    "    parser.add_argument(\n",
    "        \"--data_dir\",\n",
    "        type=str,\n",
    "        default=\"tmp/speech_dataset/\",\n",
    "        help=\"\"\"\\\n",
    "        Where to download the speech training data to.\n",
    "        \"\"\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--silence_percentage\",\n",
    "        type=float,\n",
    "        default=10.0,\n",
    "        help=\"\"\"\\\n",
    "        How much of the training data should be silence.\n",
    "        \"\"\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--unknown_percentage\",\n",
    "        type=float,\n",
    "        default=10.0,\n",
    "        help=\"\"\"\\\n",
    "        How much of the training data should be unknown words.\n",
    "        \"\"\",\n",
    "    )\n",
    "    parser.add_argument(\"--testing_percentage\", type=int, default=10, help=\"What percentage of wavs to use as a test set.\")\n",
    "    parser.add_argument(\"--validation_percentage\", type=int, default=10, help=\"What percentage of wavs to use as a validation set.\")\n",
    "    parser.add_argument(\n",
    "        \"--sample_rate\",\n",
    "        type=int,\n",
    "        default=16000,\n",
    "        help=\"Expected sample rate of the wavs\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--clip_duration_ms\",\n",
    "        type=int,\n",
    "        default=1000,\n",
    "        help=\"Expected duration in milliseconds of the wavs\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--window_size_ms\",\n",
    "        type=float,\n",
    "        default=30.0,\n",
    "        help=\"How long each spectrogram timeslice is\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--window_stride_ms\",\n",
    "        type=float,\n",
    "        default=10.0,\n",
    "        help=\"How long each spectrogram timeslice is\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--dct_coefficient_count\",\n",
    "        type=int,\n",
    "        default=40,\n",
    "        help=\"How many bins to use for the MFCC fingerprint\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--wanted_words\",\n",
    "        type=str,\n",
    "        default=\"yes,no,up,down,left,right,on,off,stop,go\",\n",
    "        help=\"Words to use (others will be added to an unknown label)\",\n",
    "    )\n",
    "    parser.add_argument(\"--model_architecture\", type=str, default=\"dnn\", help=\"What model architecture to use\")\n",
    "    parser.add_argument(\"--model_size_info\", type=int, nargs=\"+\", default=[128, 128, 128], help=\"Model dimensions - different for various models\")\n",
    "    parser.add_argument(\"--checkpoint\", type=str, help=\"Checkpoint to load the weights from.\")\n",
    "    parser.add_argument(\"--quantize\", dest=\"quantize\", action=\"store_true\", default=True, help=\"Whether to quantize the model or convert to fp32 TFLite model. Defaults to True.\")\n",
    "    parser.add_argument(\"--no-quantize\", dest=\"quantize\", action=\"store_false\", help=\"Whether to quantize the model or convert to fp32 TFLite model. Defaults to True.\")\n",
    "    parser.add_argument(\"--inference_type\", type=str, default=\"fp32\", help=\"If quantize is true, whether the model input and output is float32 or int8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7e9a04-a6a4-44e7-b448-70024f1b4f8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Widgets Control Section\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e19b751-44e3-4438-8f77-e213d81b118d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class InitConvertWidgets:\n",
    "    \"\"\"\n",
    "    A class to initialize and manage widgets for converting and deploying TensorFlow Lite models.\n",
    "    Methods:\n",
    "        create_folder(dir_path):\n",
    "            Creates a folder at the specified directory path.\n",
    "        create_command(value_list):\n",
    "            Creates a command list based on the provided values.\n",
    "        tflite_to_tflu(inf_type_s, my_f_name, tflite_name):\n",
    "            Converts a TensorFlow Lite model to TensorFlow Lite Micro.\n",
    "        tflite_to_tflu_para(inf_type_s, my_f_name, tflite_name, para_list):\n",
    "            Converts a TensorFlow Lite model to TensorFlow Lite Micro with additional parameters.\n",
    "        get_train_parameter(wanted_para_list):\n",
    "            Retrieves training parameters from the train command file.\n",
    "        deploy_tflu_to_proj(model_name, dst_loc):\n",
    "            Deploys the TensorFlow Lite Micro model to the specified project location.\n",
    "        show_main():\n",
    "            Displays the main interactive section for setting parameters and deploying models.\n",
    "        run_convert():\n",
    "            Runs the conversion process using the command list.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):  # intial the widgets elements\n",
    "\n",
    "        self.cmd_list = []  # command list\n",
    "        self.tflite_path = \"dnn_quantized.tflite\"  # tflite file name\n",
    "        self.tflu_model_dir = \"my_tflu_model\"\n",
    "        self.tflu_files_list = os.listdir(self.tflu_model_dir)\n",
    "        self.output_widgets = None\n",
    "\n",
    "        self.tflu_c_proj_saveloc = \"C:/Users/ML_M460_NuKws_SampleCode/SampleCode/tflu_kws_arm_rt_mc/Generated/DNN\"\n",
    "        self.tflu_c_proj_rundir = \"MyRunModel\"\n",
    "        self.tflu_c_proj_runname = \"runModel.cc\"\n",
    "\n",
    "        form_item_layout = Layout(\n",
    "            display=\"flex\",\n",
    "            flex_flow=\"row\",\n",
    "            justify_content=\"space-between\",\n",
    "        )\n",
    "\n",
    "        # follow parameters widgets #\n",
    "        self.a_ch = widgets.Checkbox(value=True, disabled=False, indent=False)\n",
    "        self.b_ch = widgets.Text(value=\"work/DS_CNN/1/training/best/ds_cnn_0.933_ckpt\", placeholder=\"Type something\", disabled=False)\n",
    "        self.c_ch = widgets.Checkbox(value=False, disabled=False, indent=False)\n",
    "        self.d_ch = Dropdown(value=\"fp32\", options=[\"fp32\", \"int8\"])\n",
    "        self.e_ch = widgets.Text(value=\"number_en\", placeholder=\"Type something\", disabled=False)\n",
    "        self.f_ch = widgets.Checkbox(value=True, disabled=False, indent=False)\n",
    "        self.g_ch = widgets.Button(description=\"Start to Run\", layout=Layout(width=\"50%\", height=\"30px\"), button_style=\"success\")\n",
    "        self.h_ch = widgets.Button(description=\"Start to Run\", layout=Layout(width=\"50%\", height=\"30px\"), button_style=\"success\")\n",
    "\n",
    "        form_follow_items = [\n",
    "            Box([Label(value=\"Follow the train process setting(must)\"), self.a_ch], layout=form_item_layout),\n",
    "            Box([Label(value=\"Model Location\"), self.b_ch], layout=form_item_layout),\n",
    "            Box([Label(value=\"No-Quantize\"), self.c_ch], layout=form_item_layout),\n",
    "            Box([Label(value=\"Inference Type\"), self.d_ch], layout=form_item_layout),\n",
    "            Box([Label(value=\"File Name\"), self.e_ch], layout=form_item_layout),\n",
    "            Box([Label(value=\"Parameters Inherited\"), self.f_ch], layout=form_item_layout),\n",
    "            Box([Label(value=\"Convert to tflite model\"), self.g_ch], layout=form_item_layout),\n",
    "            Box([Label(value=\"tflite to tflu\"), self.h_ch], layout=form_item_layout),\n",
    "        ]\n",
    "        self.form_box_follow_para = Box(\n",
    "            form_follow_items,\n",
    "            layout=Layout(\n",
    "                display=\"flex\",\n",
    "                flex_flow=\"column\",\n",
    "                border=\"solid 3px lightblue\",\n",
    "                align_items=\"stretch\",\n",
    "                width=\"50%\",\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # deployment parameters widgets #\n",
    "        self.a_dp = widgets.Dropdown(options=self.tflu_files_list)\n",
    "        self.b_dp = widgets.Textarea(value=self.tflu_c_proj_saveloc, placeholder=\"Type something\", disabled=False)\n",
    "        self.c_dp = widgets.Button(description=\"Deploy Model\", layout=Layout(width=\"30%\", height=\"30px\"), button_style=\"success\")\n",
    "        form_deploy_items = [\n",
    "            Box([Label(value=\"Choose the model\"), self.a_dp], layout=form_item_layout),\n",
    "            Box([Label(value=\"The location of model deployment\"), self.b_dp], layout=form_item_layout),\n",
    "            Box([Label(value=\"Copy to your proj.\"), self.c_dp], layout=form_item_layout),\n",
    "        ]\n",
    "        self.form_box_deploy_para = Box(\n",
    "            form_deploy_items,\n",
    "            layout=Layout(\n",
    "                display=\"flex\",\n",
    "                flex_flow=\"column\",\n",
    "                border=\"solid 3px lightblue\",\n",
    "                align_items=\"stretch\",\n",
    "                width=\"50%\",\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def create_folder(self, dir_path):\n",
    "        \"\"\"\n",
    "        Creates a folder at the specified directory path.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            os.mkdir(dir_path)\n",
    "        except OSError as error:\n",
    "            print(error)\n",
    "            print(\"skip create\")\n",
    "\n",
    "    def create_command(self, value_list):\n",
    "        \"\"\"\n",
    "        Creates a command list based on the provided value list and appends arguments accordingly.\n",
    "        Args:\n",
    "            value_list (list): A list of values where the first element indicates whether to read from\n",
    "                               'train_cmd.txt' and the subsequent elements correspond to command arguments.\n",
    "        \"\"\"\n",
    "        argument_list = [\"--checkpoint\", \"--no-quantize\", \"--inference_type\"]\n",
    "\n",
    "        if value_list[0]:\n",
    "            with open(\"train_cmd.txt\", \"r\", encoding=\"utf-8\") as f:  # save the complete command for train.py\n",
    "                train_cmd_line = f.read()\n",
    "            self.cmd_list = train_cmd_line.split()\n",
    "\n",
    "            if self.cmd_list != []:\n",
    "                print(\"read the train commands!\")\n",
    "            else:\n",
    "                print(\"The train_cmd.txt is empty!\")\n",
    "\n",
    "            for idx, val in enumerate(value_list[1:]):\n",
    "                if idx == 1:  # --no-quantize attr\n",
    "                    if val is True:\n",
    "                        self.cmd_list.append(argument_list[idx])\n",
    "                else:\n",
    "                    self.cmd_list.append(argument_list[idx])\n",
    "                    self.cmd_list.append(val)\n",
    "\n",
    "    def tflite_to_tflu(self, my_f_name, tflite_name):\n",
    "        \"\"\"\n",
    "        Converts a TensorFlow Lite model to a TensorFlow Lite Micro model and saves it as a C++ source file.\n",
    "        Args:\n",
    "            my_f_name (str): Base name for the output file.\n",
    "            tflite_name (str): Path to the input TensorFlow Lite model file.\n",
    "        Returns:\n",
    "            str: Path to the generated TensorFlow Lite Micro model C++ source file.\n",
    "        \"\"\"\n",
    "        out_file = my_f_name + \"_\" + tflite_name.split(\"/\")[-1].split(\".tflite\")[0] + \".cc\"\n",
    "        out_file = self.tflu_model_dir + \"/\" + out_file\n",
    "        ! python tflite_to_tflu.py --tflite_path $tflite_name --output_path $out_file\n",
    "        print(tflite_name)\n",
    "        return out_file\n",
    "\n",
    "    def tflite_to_tflu_para(self, my_f_name, tflite_name, para_list):\n",
    "        \"\"\"\n",
    "        Converts a TensorFlow Lite model to a TFLu model with additional parameters.\n",
    "        Args:\n",
    "            my_f_name (str): The base name for the output file.\n",
    "            tflite_name (str): The path to the TensorFlow Lite model file.\n",
    "            para_list (dict): A dictionary of additional parameters to be included in the conversion.\n",
    "        Returns:\n",
    "            str: The path to the generated TFLu model file.\n",
    "        \"\"\"\n",
    "        para_string = \"\"\n",
    "        for key in para_list:\n",
    "            para_string = para_string + key + \" \" + para_list[key] + \" \"\n",
    "\n",
    "        out_file = my_f_name + \"_\" + tflite_name.split(\"/\")[-1].split(\".tflite\")[0] + \".cc\"\n",
    "        out_file = self.tflu_model_dir + \"/\" + out_file\n",
    "\n",
    "        ! python kws_python/tflite_to_tflu_para.py --tflite_path $tflite_name --output_path $out_file $para_string\n",
    "        print(tflite_name)\n",
    "        return out_file\n",
    "\n",
    "    def get_train_parameter(self, wanted_para_list):\n",
    "        \"\"\"\n",
    "        Reads training parameters from a file and returns them as an ordered dictionary.\n",
    "        Args:\n",
    "            wanted_para_list (list): A list of parameter names to extract from the file.\n",
    "        Returns:\n",
    "            OrderedDict: An ordered dictionary containing the requested parameters and their values.\n",
    "        \"\"\"\n",
    "        with open(\"train_cmd.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "            train_cmd_line = f.read()\n",
    "\n",
    "        train_cmd_list = train_cmd_line.split()\n",
    "        if train_cmd_list != []:\n",
    "            print(\"read the exist train_cmd.txt\")\n",
    "        else:\n",
    "            print(\"There is no train_cmd.txt\")\n",
    "\n",
    "        cm_para_dict = OrderedDict()\n",
    "        for idx, val in enumerate(train_cmd_list):\n",
    "            if val in wanted_para_list:\n",
    "                cm_para_dict[val] = train_cmd_list[idx + 1]\n",
    "\n",
    "        return cm_para_dict\n",
    "\n",
    "    def deploy_tflu_to_proj(self, model_name, dst_loc):\n",
    "        \"\"\"\n",
    "        Deploys a TensorFlow Lite model to a specified project directory.\n",
    "        Args:\n",
    "            model_name (str): The name of the model file to be deployed.\n",
    "            dst_loc (str): The destination directory where the model should be copied.\n",
    "        \"\"\"\n",
    "        src_model_loc = os.path.join(self.tflu_model_dir, model_name)\n",
    "        if not os.path.exists(dst_loc):\n",
    "            print(\"Not exist: \")\n",
    "            print(dst_loc)\n",
    "            os.mkdir(dst_loc)\n",
    "\n",
    "        # copy to a save folder\n",
    "        shutil.copy(src_model_loc, os.path.join(dst_loc, model_name))\n",
    "        print(\"The copy saved model is here:\")\n",
    "        print(os.path.join(dst_loc, model_name))\n",
    "        print(\"\\n\")\n",
    "\n",
    "        # copy to a run folder\n",
    "        dst_run_loc = os.path.join(os.path.split(dst_loc)[0], self.tflu_c_proj_rundir)\n",
    "        self.create_folder(dst_run_loc)\n",
    "        dst_run_loc = os.path.join(dst_run_loc, self.tflu_c_proj_runname)\n",
    "        shutil.copy(src_model_loc, dst_run_loc)\n",
    "        print(\"The run model is here:\")\n",
    "        print(dst_run_loc)\n",
    "\n",
    "    def on_button_clicked_deploy_tflu(self, b):\n",
    "        \"\"\"\n",
    "        Handles the event when the deploy button is clicked.\n",
    "        \"\"\"\n",
    "        with self.output_widgets:\n",
    "            clear_output()\n",
    "            self.deploy_tflu_to_proj(self.a_dp.value, self.b_dp.value)  # model_cpy, cpy_loc\n",
    "\n",
    "    def on_button_clicked_convert_tflite(self, b):\n",
    "        \"\"\"\n",
    "        Handles the event when the convert button is clicked.\n",
    "        \"\"\"\n",
    "        with self.output_widgets:\n",
    "            clear_output()\n",
    "            self.create_command([self.a_ch.value, self.b_ch.value, self.c_ch.value, self.d_ch.value])\n",
    "            text0 = \"The convert setting is finish and saved\"\n",
    "            html0 = widgets.HTML(value=f\"<b><font color='lightblue'><font size=2>{text0}</b>\")\n",
    "            display(html0)\n",
    "            self.run_convert()\n",
    "            print(\"Finish\")\n",
    "\n",
    "    def on_button_clicked_tflu(self, b):\n",
    "        \"\"\"\n",
    "        Handles the event when the TFLU conversion button is clicked.\n",
    "        This function performs the following steps:\n",
    "        1. Clears the output widget.\n",
    "        2. Reads the training command from \"train_cmd.txt\".\n",
    "        3. Parses the command to determine the model architecture and sets the TFLite file path accordingly.\n",
    "        4. Constructs the full path to the TFLite file.\n",
    "        5. Converts the TFLite model to TFLU format, optionally including specific parameters.\n",
    "        \"\"\"\n",
    "        with self.output_widgets:\n",
    "            clear_output()\n",
    "            # update the tflite_path\n",
    "            with open(\"train_cmd.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "                train_cmd_line = f.read()\n",
    "            train_cmd_list = train_cmd_line.split()\n",
    "            for idx, val in enumerate(train_cmd_list):\n",
    "                if val == \"--model_architecture\":\n",
    "                    if not self.c_ch.value:\n",
    "                        if self.d_ch.value == \"int8\":\n",
    "                            self.tflite_path = f\"{train_cmd_list[idx + 1]}_int8quant.tflite\"\n",
    "                        else:\n",
    "                            self.tflite_path = f\"{train_cmd_list[idx + 1]}_dyquant.tflite\"\n",
    "                    else:\n",
    "                        self.tflite_path = f\"{train_cmd_list[idx + 1]}.tflite\"\n",
    "            self.tflite_path = os.path.join(self.b_ch.value.split(\"best\")[0], self.tflite_path)\n",
    "            # weather to bring kws specify parameter to fflu.cc\n",
    "            if not self.f_ch.value:\n",
    "                print(f\"Finish converting to:  {self.tflite_to_tflu(self.e_ch.value, self.tflite_path)}\")\n",
    "            else:\n",
    "                wanted_para_list = [\"--window_size_ms\", \"--window_stride_ms\", \"--dct_coefficient_count\"]\n",
    "                para_list = self.get_train_parameter(wanted_para_list)\n",
    "                print(f\"Finish converting to:  {self.tflite_to_tflu_para(self.e_ch.value, self.tflite_path, para_list)}\")\n",
    "\n",
    "    def show_main(self):  # interactive swection\n",
    "        \"\"\"\n",
    "        Displays the main interactive section for parameter selection and deployment.\n",
    "        This method creates and displays an interactive UI for selecting parameters for testing or using default values.\n",
    "        It also sets up output widgets to display results and handles button click events.\n",
    "        \"\"\"\n",
    "\n",
    "        intro_text = \"Please Choose the parameters of the testing or using the default\"\n",
    "        html_widget = widgets.HTML(value=f\"<b><font color='lightgreen'><font size=6>{intro_text}</b>\")\n",
    "        display(html_widget)\n",
    "\n",
    "        # Create an accordion and put the 2 boxes\n",
    "        accordion = widgets.Accordion(children=[self.form_box_follow_para, self.form_box_deploy_para]).add_class(\"parentstyle\")\n",
    "        # Add a custom style tag to the notebook, you can use dev tool to inspect the class names\n",
    "        display(HTML(\"<style>.parentstyle > .p-Accordion-child > .p-Collapse-header{background-color:green}</style>\"))\n",
    "        accordion.set_title(0, \"Quantizing Setting\")\n",
    "        accordion.set_title(1, \"Deployment\")\n",
    "\n",
    "        self.output_widgets = widgets.Output(layout=Layout(border=\"1px solid green\"))\n",
    "\n",
    "        def act_para(*, follow, model_loc, no_qu, inf_type, my_f_name, para_bring, model_cpy, cpy_loc):\n",
    "            # Deployment section #\n",
    "            self.tflu_files_list = os.listdir(self.tflu_model_dir)  # update the files list at each action\n",
    "            self.a_dp.options = self.tflu_files_list\n",
    "\n",
    "            # If any value is changed, clear the widgets\n",
    "            with self.output_widgets:\n",
    "                self.output_widgets.clear_output()\n",
    "\n",
    "            if no_qu:\n",
    "                self.d_ch.layout.visibility = \"hidden\"\n",
    "            else:\n",
    "                self.d_ch.layout.visibility = \"visible\"\n",
    "\n",
    "        out_inter = widgets.interactive_output(\n",
    "            act_para,\n",
    "            {\n",
    "                \"follow\": self.a_ch,\n",
    "                \"model_loc\": self.b_ch,\n",
    "                \"no_qu\": self.c_ch,\n",
    "                \"inf_type\": self.d_ch,\n",
    "                \"my_f_name\": self.e_ch,\n",
    "                \"para_bring\": self.f_ch,\n",
    "                \"model_cpy\": self.a_dp,\n",
    "                \"cpy_loc\": self.b_dp,\n",
    "                # \"d_button\": self.c_dp,\n",
    "            },\n",
    "        )\n",
    "        display(accordion, out_inter)\n",
    "        display(self.output_widgets)\n",
    "\n",
    "        # ------------------#\n",
    "        # buttoms event control in widgets.Accordion\n",
    "        # ------------------#\n",
    "\n",
    "        self.c_dp.on_click(self.on_button_clicked_deploy_tflu)\n",
    "\n",
    "        self.g_ch.on_click(self.on_button_clicked_convert_tflite)\n",
    "\n",
    "        self.h_ch.on_click(self.on_button_clicked_tflu)\n",
    "\n",
    "    def run_convert(self):\n",
    "        \"\"\"\n",
    "        Executes the conversion process for the model.\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "\n",
    "        flags_parser, _ = parser.parse_known_args(args=self.cmd_list)\n",
    "        # flags_parser, _ = parser.parse_known_args(args = ['--model_architecture','dnn','--checkpoint',r'work\\DNN\\DNN3\\training\\best\\dnn_0.835_ckpt',\n",
    "        # '--model_size_info','128','128','128'])\n",
    "        # print(flags_parser)\n",
    "        logger = logging.getLogger()\n",
    "        logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "        self.tflite_path = main_convert(flags_parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d49ed9-1d84-461a-91c8-13635009286d",
   "metadata": {},
   "source": [
    "# Run Section\n",
    "---\n",
    "- The detail description of all the parameters is here [meaning](#id-PDD).\n",
    "- `Follow the train process setting`: Please directly use the train setting of the same model (in `train_cmd.txt`).\n",
    "- After settting finish, please click `Convert to tflite model` to convert the model to tflite model.\n",
    "- The final step is to convert from tflite to tflu, please click `tflite to tflu`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3af42b7-fbe0-4771-b48b-9703f7e03fac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f7241ffab44f2ea13f15e71a18380c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<b><font color='lightgreen'><font size=6>Please Choose the parameters of the testing or using the …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.parentstyle > .p-Accordion-child > .p-Collapse-header{background-color:green}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393dee0e4de54a9ab573c2ffe1b19a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Box(children=(Box(children=(Label(value='Follow the train process setting(must)'), Checkbo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f29513456d4f7f871319e3e0f5ad0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf84b425f92e46698de0fcd0708c3585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid green', border_left='1px solid green', border_right='1px solid g…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "act = InitConvertWidgets()\n",
    "act.show_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94976b59-fba6-4a1b-b922-3d8e0d737375",
   "metadata": {},
   "source": [
    "# nuvoTon m460 for KWS running example \n",
    "---\n",
    "- There are 4 examples, 2 for offline, and 2 for online.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e2be2a-38b4-4b23-8a72-ce28311ce3af",
   "metadata": {},
   "source": [
    "## offline examples are in SampleCode/tflu_kws_arm & SampleCode/tflu_kws_arm_mc\n",
    "- tflu_kws_arm can run DNN and user can update the `#include \"raw/<keyWord>.h\"` in `main.c` for test different PCM header style data in `raw` folder.\n",
    "- tflu_kws_arm_mc can run DNN & DS-CNN model with only update `#define <which model>` in `model.h`.\n",
    "- There is a small notebook called `transferPWM.ipynb` which can help you transfer `*.wav` file to C style `<keyWord>.h`. In this way, you can test the model offline with any new sliced `*.wav` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786da572-4107-47f1-8a4e-7da110fa3eb1",
   "metadata": {},
   "source": [
    "## online examples are in SampleCode/tflu_kws_arm_rt & SampleCode/tflu_kws_arm_rt_mc\n",
    "- tflu_kws_arm_rt can run DNN. (detail: in MCU, the each inference is after 1/25 * 16000 data collected finish by PDMA through I2S and codec) \n",
    "- tflu_kws_arm_rt_mc can run DNN & DS-CNN model with only update `#define <which model>` in `model.h`. (detail: in MCU, the each inference is after 16000 data collected finish by PDMA through I2S and codec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c369ba-3c9a-43dd-9fea-f77fbe6c3443",
   "metadata": {},
   "source": [
    "<a id=\"id-PDD\"></a>\n",
    "# Parameter Description\n",
    "---\n",
    "- This notebook is basing on [ARM-software/ML-examples](https://github.com/ARM-software/ML-examples/tree/main/tflu-kws-cortex-m).\n",
    "- `Model Location`: Please fill in the trained model location which is the `*_ckpt` file, for example: work/DNN/DNN2/training/dnn_0.826_ckpt\n",
    "- `No-Quantize`: Whether to quantize the model or convert to fp32 TFLite model. Defaults to True. \n",
    "- `Inference Type`: If quantize is true, whether the model input and output is float32 or int8\n",
    "- `File Name`: The name of quantized model in c++ style. This file can be load into mcu.\n",
    "- `Parameters Inherited`: Recommend enable. This will add the KWS specify parameters into tflu.cc which user no need to update KWS parameters manually in MCU C++ code.\n",
    "- Post-training quantization: [Post-training quantization](https://www.tensorflow.org/lite/performance/post_training_quantization)\n",
    "- More description: No-Quantize = Dynamic range quantization: At inference, weights are converted from 8-bits of precision to floating point and computed using floating-point kernels. This conversion is done once and cached to reduce latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76754258-c191-41c0-b58a-f3058bc54e95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "NuEdgeWise_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
