{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ff97548",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import Section\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8c00fe7",
   "metadata": {
    "id": "e8c00fe7",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import logging\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tMWTmtEEtRy-",
   "metadata": {
    "id": "tMWTmtEEtRy-",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Location:\n",
      "C:\\Users\\CYCHEN38\\OpenNuvoton\\ML_kws_tflu\n"
     ]
    }
   ],
   "source": [
    "#folder_exc = r'C:\\Users\\USERNAME\\MICRO_ML\\ML_kws_tflu'\n",
    "\n",
    "try:  \n",
    "    from google.colab import drive\n",
    "    print('origin is:')\n",
    "    print (os.getcwd())\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    os.chdir(r'/content/drive/MyDrive/tflu-kws-cortex-m/Training')\n",
    "    print('update to:')\n",
    "    print (os.getcwd())\n",
    "    \n",
    "except ImportError:\n",
    "    print(r'Running Location:')\n",
    "    print(os.path.abspath(os.getcwd()))\n",
    "    #if (os.getcwd() != folder_exc)&(os.getcwd() != folder_exc.replace('/', \"\\\\\")):  \n",
    "    #  os.chdir(folder_exc)\n",
    "    #  print('update to:')\n",
    "    #  print (os.getcwd())\n",
    "    #else:\n",
    "    #  print('no update')  \n",
    "import data\n",
    "import models\n",
    "from test_tflite import tflite_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc7f406",
   "metadata": {
    "id": "fcc7f406",
    "tags": []
   },
   "source": [
    "# Convert Section\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86add9a7",
   "metadata": {
    "id": "86add9a7",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_REP_DATA_SAMPLES = 100  # How many samples to use for post training quantization.\n",
    "\n",
    "\n",
    "def convert(FLAGS, model_settings, audio_processor, checkpoint, quantize, inference_type, tflite_path):\n",
    "    \"\"\"Load our trained floating point model and convert it.\n",
    "\n",
    "    TFLite conversion or post training quantization is performed and the\n",
    "    resulting model is saved as a TFLite file.\n",
    "    We use samples from the validation set to do post training quantization.\n",
    "\n",
    "    Args:\n",
    "        model_settings: Dictionary of common model settings.\n",
    "        audio_processor: Audio processor class object.\n",
    "        checkpoint: Path to training checkpoint to load.\n",
    "        quantize: Whether to quantize the model or convert to fp32 TFLite model.\n",
    "        inference_type: Input/output type of the quantized model.\n",
    "        tflite_path: Output TFLite file save path.\n",
    "    \"\"\"\n",
    "    model = models.create_model(model_settings, FLAGS.model_architecture, FLAGS.model_size_info, False)\n",
    "    model.load_weights(checkpoint).expect_partial()\n",
    "\n",
    "    val_data = audio_processor.get_data(audio_processor.Modes.VALIDATION).batch(1)\n",
    "\n",
    "    def _rep_dataset():\n",
    "        \"\"\"Generator function to produce representative dataset.\"\"\"\n",
    "        i = 0\n",
    "        for mfcc, label in val_data:\n",
    "            if i > NUM_REP_DATA_SAMPLES:\n",
    "                break\n",
    "            i += 1\n",
    "            yield [mfcc]\n",
    "\n",
    "    if quantize:\n",
    "        # Quantize model and save to disk.\n",
    "        tflite_model = post_training_quantize(model, inference_type, _rep_dataset)\n",
    "        with open(tflite_path, 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "        print(f'Quantized model saved to {tflite_path}.')\n",
    "    else:\n",
    "        converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        tflite_model = converter.convert()\n",
    "        with open(tflite_path, 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "        print(f'Converted model saved to {tflite_path}.')\n",
    "\n",
    "\n",
    "def post_training_quantize(keras_model, inference_type, rep_dataset):\n",
    "    \"\"\"Perform post training quantization and returns the TFLite model ready for saving.\n",
    "\n",
    "    See https://www.tensorflow.org/lite/performance/post_training_quantization#full_integer_quantization for\n",
    "    more details.\n",
    "\n",
    "    Args:\n",
    "        keras_model: The trained tf Keras model used for post training quantization.\n",
    "        inference_type: Input/output type of the quantized model.\n",
    "        rep_dataset: Function to use as a representative dataset, must be callable.\n",
    "\n",
    "    Returns:\n",
    "        Quantized TFLite model ready for saving to disk.\n",
    "    \"\"\"\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "\n",
    "    if inference_type=='int8':\n",
    "        converter.inference_input_type = tf.int8\n",
    "        converter.inference_output_type = tf.int8\n",
    "\n",
    "    # Int8 post training quantization needs representative dataset.\n",
    "    converter.representative_dataset = rep_dataset\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    return tflite_model\n",
    "\n",
    "\n",
    "def main_convert(FLAGS):\n",
    "    model_settings = models.prepare_model_settings(len(data.prepare_words_list(FLAGS.wanted_words.split(','))),\n",
    "                                                   FLAGS.sample_rate, FLAGS.clip_duration_ms, FLAGS.window_size_ms,\n",
    "                                                   FLAGS.window_stride_ms, FLAGS.dct_coefficient_count)\n",
    "\n",
    "    audio_processor = data.AudioProcessor(data_exist=FLAGS.data_exist,\n",
    "                                          data_url=FLAGS.data_url,\n",
    "                                          data_dir=FLAGS.data_dir,\n",
    "                                          silence_percentage=FLAGS.silence_percentage,\n",
    "                                          unknown_percentage=FLAGS.unknown_percentage,\n",
    "                                          wanted_words=FLAGS.wanted_words.split(','),\n",
    "                                          validation_percentage=FLAGS.validation_percentage,\n",
    "                                          testing_percentage=FLAGS.testing_percentage,\n",
    "                                          model_settings=model_settings)\n",
    "\n",
    "    if FLAGS.quantize:\n",
    "        tflite_path = f'{FLAGS.model_architecture}_quantized.tflite'\n",
    "    else:\n",
    "        tflite_path = f'{FLAGS.model_architecture}.tflite'\n",
    "\n",
    "    # Load floating point model from checkpoint and convert it.\n",
    "    convert(FLAGS, model_settings, audio_processor, FLAGS.checkpoint,\n",
    "            FLAGS.quantize, FLAGS.inference_type, tflite_path)\n",
    "\n",
    "    # Test the newly converted model on the test set.\n",
    "    tflite_test(model_settings, audio_processor, tflite_path)\n",
    "    \n",
    "    return tflite_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e8c7a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Argument Setting\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d510d6ed",
   "metadata": {
    "id": "d510d6ed",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--data_exist',\n",
    "        type=bool,\n",
    "        default=True,\n",
    "        help='True will skip download and tar.')\n",
    "    parser.add_argument(\n",
    "        '--data_url',\n",
    "        type=str,\n",
    "        default='http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz',\n",
    "        help='Location of speech training data archive on the web.')\n",
    "    parser.add_argument(\n",
    "        '--data_dir',\n",
    "        type=str,\n",
    "        default='tmp/speech_dataset/',\n",
    "        help=\"\"\"\\\n",
    "        Where to download the speech training data to.\n",
    "        \"\"\")\n",
    "    parser.add_argument(\n",
    "        '--silence_percentage',\n",
    "        type=float,\n",
    "        default=10.0,\n",
    "        help=\"\"\"\\\n",
    "        How much of the training data should be silence.\n",
    "        \"\"\")\n",
    "    parser.add_argument(\n",
    "        '--unknown_percentage',\n",
    "        type=float,\n",
    "        default=10.0,\n",
    "        help=\"\"\"\\\n",
    "        How much of the training data should be unknown words.\n",
    "        \"\"\")\n",
    "    parser.add_argument(\n",
    "        '--testing_percentage',\n",
    "        type=int,\n",
    "        default=10,\n",
    "        help='What percentage of wavs to use as a test set.')\n",
    "    parser.add_argument(\n",
    "        '--validation_percentage',\n",
    "        type=int,\n",
    "        default=10,\n",
    "        help='What percentage of wavs to use as a validation set.')\n",
    "    parser.add_argument(\n",
    "        '--sample_rate',\n",
    "        type=int,\n",
    "        default=16000,\n",
    "        help='Expected sample rate of the wavs',)\n",
    "    parser.add_argument(\n",
    "        '--clip_duration_ms',\n",
    "        type=int,\n",
    "        default=1000,\n",
    "        help='Expected duration in milliseconds of the wavs',)\n",
    "    parser.add_argument(\n",
    "        '--window_size_ms',\n",
    "        type=float,\n",
    "        default=30.0,\n",
    "        help='How long each spectrogram timeslice is',)\n",
    "    parser.add_argument(\n",
    "        '--window_stride_ms',\n",
    "        type=float,\n",
    "        default=10.0,\n",
    "        help='How long each spectrogram timeslice is',)\n",
    "    parser.add_argument(\n",
    "        '--dct_coefficient_count',\n",
    "        type=int,\n",
    "        default=40,\n",
    "        help='How many bins to use for the MFCC fingerprint',)\n",
    "    parser.add_argument(\n",
    "        '--wanted_words',\n",
    "        type=str,\n",
    "        default='yes,no,up,down,left,right,on,off,stop,go',\n",
    "        help='Words to use (others will be added to an unknown label)',)\n",
    "    parser.add_argument(\n",
    "        '--model_architecture',\n",
    "        type=str,\n",
    "        default='dnn',\n",
    "        help='What model architecture to use')\n",
    "    parser.add_argument(\n",
    "        '--model_size_info',\n",
    "        type=int,\n",
    "        nargs=\"+\",\n",
    "        default=[128, 128, 128],\n",
    "        help='Model dimensions - different for various models')\n",
    "    parser.add_argument(\n",
    "        '--checkpoint',\n",
    "        type=str,\n",
    "        help='Checkpoint to load the weights from.')\n",
    "    parser.add_argument(\n",
    "        '--quantize',\n",
    "        dest='quantize',\n",
    "        action=\"store_true\",\n",
    "        default=True,\n",
    "        help='Whether to quantize the model or convert to fp32 TFLite model. Defaults to True.')\n",
    "    parser.add_argument(\n",
    "        '--no-quantize',\n",
    "        dest='quantize',\n",
    "        action=\"store_false\",\n",
    "        help='Whether to quantize the model or convert to fp32 TFLite model. Defaults to True.')\n",
    "    parser.add_argument(\n",
    "        '--inference_type',\n",
    "        type=str,\n",
    "        default='fp32',\n",
    "        help='If quantize is true, whether the model input and output is float32 or int8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7e9a04-a6a4-44e7-b448-70024f1b4f8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Widgets Control Section\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e19b751-44e3-4438-8f77-e213d81b118d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual, interactive\n",
    "from ipywidgets import AppLayout, Button, Layout, Box, FloatText, Textarea, Dropdown, Label, IntSlider\n",
    "from IPython.display import display, HTML\n",
    "from IPython.display import Image, clear_output\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "class init_train_widgets():\n",
    "    def __init__(self):   ###intial the widgets elements\n",
    "        \n",
    "        self.cmd_list = [] # command list\n",
    "        self.tflite_path = 'dnn_quantized.tflite' # tflite file name\n",
    "        self.tflu_model_dir = 'my_tflu_model'\n",
    "        self.tflu_files_list = os.listdir(self.tflu_model_dir)\n",
    "        \n",
    "        self.tflu_c_proj_saveLoc = 'C:/Users/ML_M460_NuKws_SampleCode/SampleCode/tflu_kws_arm_rt_mc/Generated/DNN'\n",
    "        self.tflu_c_proj_runDir = 'MyRunModel'\n",
    "        self.tflu_c_proj_runName = 'runModel.cc'\n",
    "        \n",
    "        form_item_layout = Layout(\n",
    "        display='flex',\n",
    "        flex_flow='row',\n",
    "        justify_content='space-between',\n",
    "        )\n",
    "        \n",
    "        ### follow parameters widgets ###\n",
    "        self.A_ch = widgets.Checkbox(value=True, disabled=False, indent=False)\n",
    "        self.B_ch = widgets.Text(value='work/DNN/DNN2/training/best/dnn_0.898_ckpt', placeholder='Type something', disabled=False)\n",
    "        self.C_ch = widgets.Checkbox(value=False, disabled=False, indent=False)\n",
    "        self.D_ch = Dropdown(value='fp32', options=['fp32', 'int8'])  \n",
    "        self.E_ch = widgets.Text(value='number_en_para', placeholder='Type something', disabled=False)\n",
    "        self.F_ch = widgets.Checkbox(value=True, disabled=False, indent=False)\n",
    "        self.G_ch = widgets.Button(description='Start to Run', layout=Layout(width='50%', height='30px'), button_style='success')\n",
    "        self.H_ch = widgets.Button(description='Start to Run', layout=Layout(width='50%', height='30px'), button_style='success')\n",
    "        \n",
    "        form_follow_items = [\n",
    "            Box([Label(value = 'Follow the train process setting(must)'), self.A_ch], layout=form_item_layout),\n",
    "            Box([Label(value = 'Model Location'), self.B_ch], layout=form_item_layout),\n",
    "            Box([Label(value = 'No-Quantize'), self.C_ch], layout=form_item_layout),\n",
    "            Box([Label(value = 'Inference Type'), self.D_ch], layout=form_item_layout),\n",
    "            Box([Label(value = 'File Name'), self.E_ch], layout=form_item_layout),\n",
    "            Box([Label(value = 'Parameters Inherited'), self.F_ch], layout=form_item_layout),\n",
    "            Box([Label(value = 'Convert to tflite model'), self.G_ch], layout=form_item_layout),\n",
    "            Box([Label(value = 'tflite to tflu'), self.H_ch], layout=form_item_layout)\n",
    "        ]    \n",
    "        self.form_box_follow_para = Box(form_follow_items, layout=Layout(\n",
    "            display='flex',\n",
    "            flex_flow='column',\n",
    "            border='solid 3px lightblue',\n",
    "            align_items='stretch',\n",
    "            width='50%',\n",
    "        ))\n",
    "        \n",
    "        ### deployment parameters widgets ###\n",
    "        self.A_dp = widgets.Dropdown(options=self.tflu_files_list)\n",
    "        self.B_dp = widgets.Textarea(value=self.tflu_c_proj_saveLoc, placeholder='Type something', disabled=False)\n",
    "        self.C_dp = widgets.ToggleButton(description='Deploy Model', layout=Layout(width='30%', height='30px'), button_style='success')\n",
    "        form_deploy_items = [\n",
    "            Box([Label(value = 'Choose the model'), self.A_dp], layout=form_item_layout),\n",
    "            Box([Label(value = 'The location of model deployment'), self.B_dp], layout=form_item_layout),\n",
    "            Box([Label(value = 'Copy to your proj.'), self.C_dp], layout=form_item_layout)\n",
    "        ]    \n",
    "        self.form_box_deploy_para = Box(form_deploy_items, layout=Layout(\n",
    "            display='flex',\n",
    "            flex_flow='column',\n",
    "            border='solid 3px lightblue',\n",
    "            align_items='stretch',\n",
    "            width='50%',\n",
    "        ))\n",
    "     \n",
    "    def create_folder(self, dir_path):\n",
    "        try:\n",
    "            os.mkdir(dir_path)\n",
    "        except OSError as error:\n",
    "            print(error)\n",
    "            print('skip create')\n",
    "    \n",
    "    def create_command(self, value_list):\n",
    "        argument_list = ['--checkpoint', '--no-quantize', '--inference_type']\n",
    "        cm_dict = OrderedDict()\n",
    "             \n",
    "        if(value_list[0]):        \n",
    "            with open('train_cmd.txt','r') as f:  #save the complete command for train.py\n",
    "                train_cmd_line = f.read()\n",
    "            self.cmd_list = train_cmd_line.split()\n",
    "            \n",
    "            if(self.cmd_list != []):\n",
    "                print('read the train commands!')\n",
    "            else:\n",
    "                print('The train_cmd.txt is empty!')\n",
    "                \n",
    "            for idx, val in enumerate(value_list[1:]):\n",
    "                if(idx == 1):   #--no-quantize attr\n",
    "                    if(val == True):\n",
    "                        self.cmd_list.append(argument_list[idx])\n",
    "                else:    \n",
    "                    self.cmd_list.append(argument_list[idx])\n",
    "                    self.cmd_list.append(val)\n",
    "        #print(self.cmd_list)\n",
    "        \n",
    "    def tflite_to_tflu(self, inf_type_s, my_f_name, tflite_name):\n",
    "        out_file = 'tflu_' + inf_type_s + '_' +my_f_name + '.cc'\n",
    "        out_file = self.tflu_model_dir + '/' + out_file\n",
    "        ! python tflite_to_tflu.py --tflite_path $tflite_name --output_path $out_file\n",
    "        print(tflite_name)\n",
    "        return out_file\n",
    "    \n",
    "    def tflite_to_tflu_para(self, inf_type_s, my_f_name, tflite_name, para_list):\n",
    "        para_string = ''\n",
    "        for key in para_list:\n",
    "            para_string = para_string + key + ' ' + para_list[key] + ' '\n",
    "        \n",
    "        out_file = 'tflu_' + inf_type_s + '_' +my_f_name + '.cc'\n",
    "        out_file = self.tflu_model_dir + '/' + out_file\n",
    "        ! python tflite_to_tflu_para.py --tflite_path $tflite_name --output_path $out_file $para_string\n",
    "        print(tflite_name)\n",
    "        return out_file\n",
    "    \n",
    "    def get_train_parameter(self, wanted_para_list):\n",
    "            with open('train_cmd.txt','r') as f:\n",
    "                train_cmd_line = f.read()\n",
    "                \n",
    "            train_cmd_list = train_cmd_line.split()\n",
    "            if(train_cmd_list != []):\n",
    "                print('read the exist train_cmd.txt')\n",
    "            else:\n",
    "                print('There is no train_cmd.txt')\n",
    "            \n",
    "            cm_para_dict = OrderedDict()\n",
    "            for idx, val in enumerate(train_cmd_list):\n",
    "                if val in wanted_para_list:\n",
    "                    cm_para_dict[val] = train_cmd_list[idx + 1] \n",
    "                        \n",
    "            return cm_para_dict\n",
    "    \n",
    "    def deploy_tflu_to_proj(self, model_name, dst_loc):\n",
    "        src_model_loc = os.path.join(self.tflu_model_dir, model_name)\n",
    "        if not os.path.exists(dst_loc):\n",
    "            print('Not exist: ')\n",
    "            print(dst_loc)\n",
    "            os.mkdir(dst_loc)\n",
    "            \n",
    "        ###copy to a save folder    \n",
    "        shutil.copy(src_model_loc, os.path.join(dst_loc, model_name))\n",
    "        print('The copy saved model is here:')\n",
    "        print(os.path.join(dst_loc, model_name))\n",
    "        print('\\n')\n",
    "        \n",
    "        ###copy to a run folder\n",
    "        dst_run_loc = os.path.join(os.path.split(dst_loc)[0], self.tflu_c_proj_runDir)\n",
    "        self.create_folder(dst_run_loc)\n",
    "        dst_run_loc = os.path.join(dst_run_loc, self.tflu_c_proj_runName)\n",
    "        shutil.copy(src_model_loc, dst_run_loc) \n",
    "        print('The run model is here:')\n",
    "        print(dst_run_loc)\n",
    "        \n",
    "    def show_main(self):   ###interactive swection\n",
    "        \n",
    "        intro_text = 'Please Choose the parameters of the testing or using the default'\n",
    "        htmlWidget = widgets.HTML(value = f\"<b><font color='lightblue'><font size=4>{intro_text}</b>\")\n",
    "        display(htmlWidget)\n",
    "        \n",
    "        #Create an accordion and put the 2 boxes\n",
    "        accordion = widgets.Accordion(children=[self.form_box_follow_para, self.form_box_deploy_para]).add_class(\"parentstyle\")\n",
    "        #Add a custom style tag to the notebook, you can use dev tool to inspect the class names\n",
    "        display(HTML(\"<style>.parentstyle > .p-Accordion-child > .p-Collapse-header{background-color:green}</style>\"))\n",
    "        accordion.set_title(0, 'Quantizing Setting')\n",
    "        accordion.set_title(1, 'Deployment')\n",
    "        \n",
    "        \n",
    "        def act_para(follow,model_loc,no_qu,inf_type,my_f_name,para_bring,model_cpy,cpy_loc,d_button):\n",
    "            out = widgets.Output()\n",
    "            \n",
    "            ###Deployment section###\n",
    "            self.tflu_files_list = os.listdir(self.tflu_model_dir) ### update the files list at each action\n",
    "            self.A_dp.options = self.tflu_files_list\n",
    "            \n",
    "            if d_button:  \n",
    "                with out:\n",
    "                    #print('yes\\n')\n",
    "                    self.deploy_tflu_to_proj(model_cpy, cpy_loc)\n",
    "            else:\n",
    "                with out:\n",
    "                    out.clear_output()\n",
    "                    #print('no')\n",
    "                    \n",
    "            display(out)\n",
    "                   \n",
    "        \n",
    "        out = widgets.interactive_output(act_para, {'follow': self.A_ch, 'model_loc': self.B_ch, 'no_qu': self.C_ch, \n",
    "                                                    'inf_type': self.D_ch, 'my_f_name': self.E_ch, 'para_bring' : self.F_ch,\n",
    "                                                    'model_cpy':self.A_dp, 'cpy_loc':self.B_dp, 'd_button':self.C_dp\n",
    "                                                    })\n",
    "        display(accordion, out)\n",
    "        \n",
    "        #------------------#\n",
    "        # buttoms event control in widgets.Accordion\n",
    "        #------------------# \n",
    "        output_button = widgets.Output(layout=Layout(border = '1px solid green'))\n",
    "        display(output_button)\n",
    "        def on_button_clicked_convert_tflite(b):\n",
    "            with output_button:\n",
    "                clear_output()\n",
    "                \n",
    "                self.create_command([self.A_ch.value, self.B_ch.value, self.C_ch.value, self.D_ch.value])\n",
    "                text0 = 'The convert setting is finish and saved'\n",
    "                html0= widgets.HTML(value = f\"<b><font color='lightblue'><font size=2>{text0}</b>\")\n",
    "                display(html0)\n",
    "                \n",
    "                self.run_convert()\n",
    "                print('Finish')    \n",
    "        self.G_ch.on_click(on_button_clicked_convert_tflite)\n",
    "         \n",
    "        def on_button_clicked_tflu(b):\n",
    "            with output_button:\n",
    "                clear_output()\n",
    "                ### update the tflite_path\n",
    "                with open('train_cmd.txt','r') as f:\n",
    "                    train_cmd_line = f.read()\n",
    "                train_cmd_list = train_cmd_line.split()\n",
    "                for idx, val in enumerate(train_cmd_list):\n",
    "                    if val == '--model_architecture':\n",
    "                        if not self.C_ch.value:\n",
    "                            self.tflite_path = f'{train_cmd_list[idx + 1]}_quantized.tflite'\n",
    "                        else:\n",
    "                            self.tflite_path = f'{train_cmd_list[idx + 1]}.tflite'\n",
    "            \n",
    "                ### weather to bring kws specify parameter to fflu.cc\n",
    "                if not self.F_ch.value:\n",
    "                    print('Finish converting to:  {}'.format(self.tflite_to_tflu(self.D_ch.value, self.E_ch.value, self.tflite_path)))\n",
    "                else:\n",
    "                    wanted_para_list = ['--window_size_ms', '--window_stride_ms', '--dct_coefficient_count']\n",
    "                    para_list = self.get_train_parameter(wanted_para_list)\n",
    "                    print('Finish converting to:  {}'.format(\n",
    "                        self.tflite_to_tflu_para(self.D_ch.value, self.E_ch.value, self.tflite_path, para_list)))  \n",
    "        self.H_ch.on_click(on_button_clicked_tflu)        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def run_convert(self):   ###run the mainprogram\n",
    "        \n",
    "        FLAGS, _ = parser.parse_known_args(args = self.cmd_list)\n",
    "        #FLAGS, _ = parser.parse_known_args(args = ['--model_architecture','dnn','--checkpoint',r'work\\DNN\\DNN3\\training\\best\\dnn_0.835_ckpt',\n",
    "        #'--model_size_info','128','128','128'])\n",
    "        #print(FLAGS)\n",
    "        logger = logging.getLogger()\n",
    "        logger.setLevel(logging.CRITICAL)\n",
    "\n",
    "        self.tflite_path = main_convert(FLAGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d49ed9-1d84-461a-91c8-13635009286d",
   "metadata": {},
   "source": [
    "# Run Section\n",
    "---\n",
    "- The detail description of all the parameters is here [meaning](#id-PDD).\n",
    "- `Follow the train process setting`: Please directly use the train setting of the same model (in `train_cmd.txt`).\n",
    "- After settting finish, please click `Convert to tflite model` to convert the model to tflite model.\n",
    "- The final step is to convert from tflite to tflu, please click `tflite to tflu`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3af42b7-fbe0-4771-b48b-9703f7e03fac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b12291c2614f64ab1b82b33966e0e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<b><font color='lightblue'><font size=4>Please Choose the parameters of the testing or using the d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.parentstyle > .p-Accordion-child > .p-Collapse-header{background-color:green}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba4b864572d0478b9c633de04bdfd9b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Box(children=(Box(children=(Label(value='Follow the train process setting(must)'), Checkbo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce3c77cda8544b380e25947f626841b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3225f73664841408443b7b8ea77f27a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='1px solid green'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "act = init_train_widgets()\n",
    "act.show_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94976b59-fba6-4a1b-b922-3d8e0d737375",
   "metadata": {},
   "source": [
    "# nuvoTon m460 for KWS running example \n",
    "---\n",
    "- There are 4 examples, 2 for offline, and 2 for online.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e2be2a-38b4-4b23-8a72-ce28311ce3af",
   "metadata": {},
   "source": [
    "## offline examples are in SampleCode/tflu_kws_arm & SampleCode/tflu_kws_arm_mc\n",
    "- tflu_kws_arm can run DNN and user can update the `#include \"raw/<keyWord>.h\"` in `main.c` for test different PCM header style data in `raw` folder.\n",
    "- tflu_kws_arm_mc can run DNN & DS-CNN model with only update `#define <which model>` in `model.h`.\n",
    "- There is a small notebook called `transferPWM.ipynb` which can help you transfer `*.wav` file to C style `<keyWord>.h`. In this way, you can test the model offline with any new sliced `*.wav` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786da572-4107-47f1-8a4e-7da110fa3eb1",
   "metadata": {},
   "source": [
    "## online examples are in SampleCode/tflu_kws_arm_rt & SampleCode/tflu_kws_arm_rt_mc\n",
    "- tflu_kws_arm_rt can run DNN. (detail: in MCU, the each inference is after 1/25 * 16000 data collected finish by PDMA through I2S and codec) \n",
    "- tflu_kws_arm_rt_mc can run DNN & DS-CNN model with only update `#define <which model>` in `model.h`. (detail: in MCU, the each inference is after 16000 data collected finish by PDMA through I2S and codec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c369ba-3c9a-43dd-9fea-f77fbe6c3443",
   "metadata": {},
   "source": [
    "<a id=\"id-PDD\"></a>\n",
    "# Parameter Description\n",
    "---\n",
    "- This notebook is basing on [ARM-software/ML-examples](https://github.com/ARM-software/ML-examples/tree/main/tflu-kws-cortex-m).\n",
    "- `Model Location`: Please fill in the trained model location which is the `*_ckpt` file, for example: work/DNN/DNN2/training/dnn_0.826_ckpt\n",
    "- `No-Quantize`: Whether to quantize the model or convert to fp32 TFLite model. Defaults to True. \n",
    "- `Inference Type`: If quantize is true, whether the model input and output is float32 or int8\n",
    "- `File Name`: The name of quantized model in c++ style. This file can be load into mcu.\n",
    "- `Parameters Inherited`: Recommend enable. This will add the KWS specify parameters into tflu.cc which user no need to update KWS parameters manually in MCU C++ code.\n",
    "- Post-training quantization: [Post-training quantization](https://www.tensorflow.org/lite/performance/post_training_quantization)\n",
    "- More description: No-Quantize = Dynamic range quantization: At inference, weights are converted from 8-bits of precision to floating point and computed using floating-point kernels. This conversion is done once and cached to reduce latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76754258-c191-41c0-b58a-f3058bc54e95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
