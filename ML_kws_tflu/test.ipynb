{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ff97548",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import Section\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8c00fe7",
   "metadata": {
    "id": "e8c00fe7",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-19 09:12:41.456406: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-19 09:12:41.557810: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-08-19 09:12:41.557826: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-08-19 09:12:41.572796: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-08-19 09:12:41.939620: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-19 09:12:41.939727: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2024-08-19 09:12:41.939733: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tMWTmtEEtRy-",
   "metadata": {
    "id": "tMWTmtEEtRy-",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Location:\n",
      "/ML_KWS/ML_kws_tflu\n"
     ]
    }
   ],
   "source": [
    "#folder_exc = r'C:\\Users\\USERNAME\\MICRO_ML\\ML_kws_tflu'\n",
    "\n",
    "try:  \n",
    "    from google.colab import drive\n",
    "    print('origin is:')\n",
    "    print (os.getcwd())\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    os.chdir(r'/content/drive/MyDrive/tflu-kws-cortex-m/Training')\n",
    "    print('update to:')\n",
    "    print (os.getcwd())\n",
    "    \n",
    "except ImportError:\n",
    "    print(r'Running Location:')\n",
    "    print(os.path.abspath(os.getcwd()))\n",
    "    #if (os.getcwd() != folder_exc)&(os.getcwd() != folder_exc.replace('/', \"\\\\\")):  \n",
    "    #  os.chdir(folder_exc)\n",
    "    #  print('update to:')\n",
    "    #  print (os.getcwd())\n",
    "    #else:\n",
    "    #  print('no update')  \n",
    "from kws_python import data\n",
    "from kws_python import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc7f406",
   "metadata": {
    "id": "fcc7f406",
    "tags": []
   },
   "source": [
    "# Test Section\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86add9a7",
   "metadata": {
    "id": "86add9a7",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test(FLAGS):\n",
    "    \"\"\"Calculate accuracy and confusion matrices on validation and test sets.\n",
    "\n",
    "    Model is created and weights loaded from supplied command line arguments.\n",
    "    \"\"\"\n",
    "    model_settings = models.prepare_model_settings(len(data.prepare_words_list(FLAGS.wanted_words.split(','))),\n",
    "                                                   FLAGS.sample_rate, FLAGS.clip_duration_ms, FLAGS.window_size_ms,\n",
    "                                                   FLAGS.window_stride_ms, FLAGS.dct_coefficient_count)\n",
    "\n",
    "    model = models.create_model(model_settings, FLAGS.model_architecture, FLAGS.model_size_info, False)\n",
    "\n",
    "    audio_processor = data.AudioProcessor(data_exist=FLAGS.data_exist,\n",
    "                                          data_url=FLAGS.data_url,\n",
    "                                          data_dir=FLAGS.data_dir,\n",
    "                                          silence_percentage=FLAGS.silence_percentage,\n",
    "                                          unknown_percentage=FLAGS.unknown_percentage,\n",
    "                                          wanted_words=FLAGS.wanted_words.split(','),\n",
    "                                          validation_percentage=FLAGS.validation_percentage,\n",
    "                                          testing_percentage=FLAGS.testing_percentage,\n",
    "                                          model_settings=model_settings)\n",
    "    print(FLAGS.checkpoint)\n",
    "    model.load_weights(FLAGS.checkpoint).expect_partial()\n",
    "\n",
    "    # Evaluate on validation set.\n",
    "    print(\"Running testing on validation set...\")\n",
    "    val_data = audio_processor.get_data(audio_processor.Modes.VALIDATION).batch(FLAGS.batch_size)\n",
    "    expected_indices = np.concatenate([y for x, y in val_data])\n",
    "\n",
    "    predictions = model.predict(val_data)\n",
    "    predicted_indices = tf.argmax(predictions, axis=1)\n",
    "\n",
    "    val_accuracy = calculate_accuracy(predicted_indices, expected_indices)\n",
    "    confusion_matrix = tf.math.confusion_matrix(expected_indices, predicted_indices,\n",
    "                                                num_classes=model_settings['label_count'])\n",
    "    print(confusion_matrix.numpy())\n",
    "    print(f'Validation accuracy = {val_accuracy * 100:.2f}%'\n",
    "          f'(N={audio_processor.set_size(audio_processor.Modes.VALIDATION)})')\n",
    "\n",
    "    # Evaluate on testing set.\n",
    "    print(\"Running testing on test set...\")\n",
    "    test_data = audio_processor.get_data(audio_processor.Modes.TESTING).batch(FLAGS.batch_size)\n",
    "    expected_indices = np.concatenate([y for x, y in test_data])\n",
    "\n",
    "    predictions = model.predict(test_data)\n",
    "    predicted_indices = tf.argmax(predictions, axis=1)\n",
    "\n",
    "    test_accuracy = calculate_accuracy(predicted_indices, expected_indices)\n",
    "    confusion_matrix = tf.math.confusion_matrix(expected_indices, predicted_indices,\n",
    "                                                num_classes=model_settings['label_count'])\n",
    "    print(confusion_matrix.numpy())\n",
    "    print(f'Test accuracy = {test_accuracy * 100:.2f}%'\n",
    "          f'(N={audio_processor.set_size(audio_processor.Modes.TESTING)})')\n",
    "    \n",
    "def calculate_accuracy(predicted_indices, expected_indices):\n",
    "    \"\"\"Calculates and returns accuracy.\n",
    "\n",
    "    Args:\n",
    "        predicted_indices: List of predicted integer indices.\n",
    "        expected_indices: List of expected integer indices.\n",
    "\n",
    "    Returns:\n",
    "        Accuracy value between 0 and 1.\n",
    "    \"\"\"\n",
    "    correct_prediction = tf.equal(predicted_indices, expected_indices)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    return accuracy    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e8c7a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Argument Setting\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d510d6ed",
   "metadata": {
    "id": "d510d6ed",
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--data_exist',\n",
    "        type=bool,\n",
    "        default=True,\n",
    "        help='True will skip download and tar.')\n",
    "    parser.add_argument(\n",
    "        '--data_url',\n",
    "        type=str,\n",
    "        default='http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz',\n",
    "        help='Location of speech training data archive on the web.')\n",
    "    parser.add_argument(\n",
    "        '--data_dir',\n",
    "        type=str,\n",
    "        default='tmp/speech_dataset/',\n",
    "        help=\"\"\"\\\n",
    "        Where to download the speech training data to.\n",
    "        \"\"\")\n",
    "    parser.add_argument(\n",
    "        '--silence_percentage',\n",
    "        type=float,\n",
    "        default=10.0,\n",
    "        help=\"\"\"\\\n",
    "        How much of the training data should be silence.\n",
    "        \"\"\")\n",
    "    parser.add_argument(\n",
    "        '--unknown_percentage',\n",
    "        type=float,\n",
    "        default=10.0,\n",
    "        help=\"\"\"\\\n",
    "        How much of the training data should be unknown words.\n",
    "        \"\"\")\n",
    "    parser.add_argument(\n",
    "        '--testing_percentage',\n",
    "        type=int,\n",
    "        default=10,\n",
    "        help='What percentage of wavs to use as a test set.')\n",
    "    parser.add_argument(\n",
    "        '--validation_percentage',\n",
    "        type=int,\n",
    "        default=10,\n",
    "        help='What percentage of wavs to use as a validation set.')\n",
    "    parser.add_argument(\n",
    "        '--sample_rate',\n",
    "        type=int,\n",
    "        default=16000,\n",
    "        help='Expected sample rate of the wavs',)\n",
    "    parser.add_argument(\n",
    "        '--clip_duration_ms',\n",
    "        type=int,\n",
    "        default=1000,\n",
    "        help='Expected duration in milliseconds of the wavs',)\n",
    "    parser.add_argument(\n",
    "        '--window_size_ms',\n",
    "        type=float,\n",
    "        default=30.0,\n",
    "        help='How long each spectrogram timeslice is',)\n",
    "    parser.add_argument(\n",
    "        '--window_stride_ms',\n",
    "        type=float,\n",
    "        default=10.0,\n",
    "        help='How long each spectrogram timeslice is',)\n",
    "    parser.add_argument(\n",
    "        '--dct_coefficient_count',\n",
    "        type=int,\n",
    "        default=40,\n",
    "        help='How many bins to use for the MFCC fingerprint',)\n",
    "    parser.add_argument(\n",
    "        '--batch_size',\n",
    "        type=int,\n",
    "        default=100,\n",
    "        help='How many items to train with at once',)\n",
    "    parser.add_argument(\n",
    "        '--wanted_words',\n",
    "        type=str,\n",
    "        default='yes,no,up,down,left,right,on,off,stop,go',\n",
    "        help='Words to use (others will be added to an unknown label)',)\n",
    "    parser.add_argument(\n",
    "        '--checkpoint',\n",
    "        type=str,\n",
    "        help='Checkpoint to load the weights from.')\n",
    "    parser.add_argument(\n",
    "        '--model_architecture',\n",
    "        type=str,\n",
    "        default='dnn',\n",
    "        help='What model architecture to use')\n",
    "    parser.add_argument(\n",
    "        '--model_size_info',\n",
    "        type=int,\n",
    "        nargs=\"+\",\n",
    "        default=[128, 128, 128],\n",
    "        help='Model dimensions - different for various models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7e9a04-a6a4-44e7-b448-70024f1b4f8f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Widgets Control Section\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e19b751-44e3-4438-8f77-e213d81b118d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual, interactive\n",
    "from ipywidgets import AppLayout, Button, Layout, Box, FloatText, Textarea, Dropdown, Label, IntSlider\n",
    "from IPython.display import display, HTML\n",
    "from IPython.display import Image, clear_output\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "class init_train_widgets():\n",
    "    def __init__(self):   ###intial the widgets elements\n",
    "          \n",
    "        form_item_layout = Layout(\n",
    "        display='flex',\n",
    "        flex_flow='row',\n",
    "        justify_content='space-between',\n",
    "        )\n",
    "        \n",
    "        ### follow parameters widgets ###\n",
    "        self.A_ch = widgets.Checkbox(value=True, disabled=False, indent=False)\n",
    "        self.B_ch = widgets.Text(value='work/DS_CNN/1/training/best/ds_cnn_0.933_ckpt', placeholder='Type something', disabled=False)\n",
    "        form_follow_items = [\n",
    "            Box([Label(value = 'Follow the train process setting(recommend)'), self.A_ch], layout=form_item_layout),\n",
    "            Box([Label(value = 'Model location'), self.B_ch], layout=form_item_layout)\n",
    "        ]    \n",
    "        self.form_box_follow_para = Box(form_follow_items, layout=Layout(\n",
    "            display='flex',\n",
    "            flex_flow='column',\n",
    "            border='solid 3px lightblue',\n",
    "            align_items='stretch',\n",
    "            width='50%',\n",
    "        ))\n",
    "\n",
    "        ### train model parameters widgets ###\n",
    "        self.A_ta = Dropdown(options=['dnn', 'cnn', 'ds_cnn', 'basic_lstm'])\n",
    "        self.B_ta = widgets.BoundedIntText(value=10, min=0, max=50.0, step=1, disabled=False)\n",
    "        self.C_ta = widgets.BoundedIntText(value=10, min=0, max=50.0, step=1, disabled=False)\n",
    "        self.G_ta = widgets.IntSlider(value=100, min=50, max=1000, step=50)\n",
    "        self.H_ta = widgets.Text(value='128,128,128', placeholder='Type something', description='Int:', disabled=False)\n",
    "        self.I_ta = widgets.Textarea(value='yes,no,up,down,left,right,on,off,stop,go', placeholder='Type something', description='String:', disabled=False)\n",
    "        \n",
    "        form_train_items = [\n",
    "            Box([Label(value = 'Model Architecture'), self.A_ta], layout=form_item_layout),\n",
    "            Box([Label(value = 'Testing percentage'), self.B_ta], layout=form_item_layout),\n",
    "            Box([Label(value = 'Validation percentage'), self.C_ta], layout=form_item_layout),\n",
    "            Box([Label(value = 'Batch size'), self.G_ta], layout=form_item_layout),\n",
    "            Box([Label(value = 'Model size (dimension)'), self.H_ta], layout=form_item_layout),\n",
    "            Box([Label(value = 'Wanted words'), self.I_ta], layout=form_item_layout),\n",
    "        ]\n",
    "        \n",
    "        self.form_box_train_para = Box(form_train_items, layout=Layout(\n",
    "            display='flex',\n",
    "            flex_flow='column',\n",
    "            border='solid 3px lightblue',\n",
    "            align_items='stretch',\n",
    "            width='50%',\n",
    "        ))\n",
    "        \n",
    "        \n",
    "        ### data parameters widgets ###\n",
    "        self.A_da = IntSlider(value=10, min=10, max=50)\n",
    "        self.B_da = widgets.Checkbox(value=True, disabled=False, indent=False)\n",
    "        self.C_da = widgets.FloatSlider(value=0.1, min=0.0, max=1.0)\n",
    "        self.D_da = widgets.FloatSlider(value=0.8, min=0.0, max=1.0)\n",
    "        self.E_da = widgets.FloatSlider(value=10.0, min=0.0, max=30.0)\n",
    "        self.F_da = widgets.FloatSlider(value=10.0, min=0.0, max=30.0)\n",
    "        self.G_da = widgets.FloatSlider(value=100.0, min=50.0, max=200.0, step=10.0)\n",
    "        self.H_da = widgets.IntSlider(value=16000, min=16000, max=32000, step=16000)\n",
    "        self.I_da = widgets.IntSlider(value=1000, min=800, max=3000, step=200)\n",
    "        self.J_da = widgets.IntSlider(value=40, min=10, max=100, step=10)\n",
    "        self.K_da = widgets.IntSlider(value=40, min=10, max=100, step=10)\n",
    "        \n",
    "        form_data_items = [\n",
    "            Box([Label(value = 'DCT coefficient count'), self.A_da], layout=form_item_layout),\n",
    "            Box([Label(value = 'Data exist'), self.B_da], layout=form_item_layout),\n",
    "            Box([Label(value = 'Background volume'), self.C_da], layout=form_item_layout),\n",
    "            Box([Label(value = 'Background frequency'), self.D_da], layout=form_item_layout),\n",
    "            Box([Label(value = 'Silence percentage'), self.E_da], layout=form_item_layout),\n",
    "            Box([Label(value = 'Unknown percentage'), self.F_da], layout=form_item_layout),\n",
    "            Box([Label(value = 'Time shift (ms)'), self.G_da], layout=form_item_layout),\n",
    "            Box([Label(value = 'Sample rate'), self.H_da], layout=form_item_layout),\n",
    "            Box([Label(value = 'Clip duration (ms)'), self.I_da], layout=form_item_layout),\n",
    "            Box([Label(value = 'Window size (ms)'), self.J_da], layout=form_item_layout),\n",
    "            Box([Label(value = 'Window stride (ms)'), self.K_da], layout=form_item_layout)\n",
    "        ]\n",
    "        \n",
    "        self.form_box_data_para = Box(form_data_items, layout=Layout(\n",
    "            display='flex',\n",
    "            flex_flow='column',\n",
    "            border='solid 3px lightblue',\n",
    "            align_items='stretch',\n",
    "            width='50%',\n",
    "        ))\n",
    "    \n",
    "    def create_command(self, cm_list):\n",
    "        argument_list = ['--checkpoint',\n",
    "                         '--model_architecture', '--testing_percentage', '--validation_percentage',  \n",
    "                         '-batch_size', '--model_size_info', '--wanted_words', \n",
    "                         '--dct_coefficient_count', '--data_exist', '--background_volume','--background_frequency', '--silence_percentage', \n",
    "                         '--unknown_percentage', '--time_shift_ms', '--sample_rate','--clip_duration_ms', '--window_size_ms', '--window_stride_ms']\n",
    "        cm_dict = OrderedDict()\n",
    "        \n",
    "        if(cm_list[0] == True):      #directly use train process setting\n",
    "            cm_dict[argument_list[0]] = cm_list[1]  #save the checkpoint\n",
    "            \n",
    "            with open('train_cmd.txt','r') as f:\n",
    "                train_cmd_line = f.read()\n",
    "            train_cmd_list = train_cmd_line.split()\n",
    "            if(train_cmd_list != []):\n",
    "                print('read the exist train_cmd.txt')\n",
    "            \n",
    "            for idx, val in enumerate(train_cmd_list):\n",
    "                if val in argument_list:    #find the needed attrs\n",
    "                    \n",
    "                    if val == '--model_size_info':\n",
    "                        i = 1;\n",
    "                        m_list = []\n",
    "                        while (train_cmd_list[idx + i].find('--') == -1):\n",
    "                            m_list.append(train_cmd_list[idx + i])\n",
    "                            i = i+1\n",
    "                        cm_dict[val] = m_list   \n",
    "                    else:\n",
    "                        cm_dict[val] = train_cmd_list[idx + 1] \n",
    "        else:\n",
    "             for idx, val in enumerate(cm_list[1:]):\n",
    "                    print(idx,val)\n",
    "                    if argument_list[idx] == '--model_size_info':  #transfer from single string to list format\n",
    "                        cm_dict[argument_list[idx]] = val.split(',')\n",
    "                    else:\n",
    "                        cm_dict[argument_list[idx]] = val    \n",
    "             \n",
    "        with open('test_cmd.txt','w') as f:  #save the complete command for test.py\n",
    "            for key, value in cm_dict.items():\n",
    "                \n",
    "                if(type(value) == list):\n",
    "                    f.write('%s ' % (key))\n",
    "                    for i in range(len(value)):\n",
    "                        f.write('%s ' % (value[i]))\n",
    "                else:    \n",
    "                    f.write('%s %s ' % (key, value))\n",
    "     \n",
    "        return 0\n",
    "        \n",
    "    def show_main(self):   ###interactive swection\n",
    "        \n",
    "        intro_text = 'Please Choose the parameters of the testing or using the default'\n",
    "        htmlWidget = widgets.HTML(value = f\"<b><font color='lightblue'><font size=4>{intro_text}</b>\")\n",
    "        display(htmlWidget)\n",
    "        \n",
    "        #Create an accordion and put the 2 boxes\n",
    "        accordion = widgets.Accordion(children=[self.form_box_follow_para, self.form_box_train_para, self.form_box_data_para]).add_class(\"parentstyle\")\n",
    "        \n",
    "        #Add a custom style tag to the notebook, you can use dev tool to inspect the class names\n",
    "        display(HTML(\"<style>.parentstyle > .p-Accordion-child > .p-Collapse-header{background-color:green}</style>\"))\n",
    "        accordion.set_title(0, 'Follow Setting')\n",
    "        accordion.set_title(1, 'Test Setting')\n",
    "        accordion.set_title(2, 'Data Setting')\n",
    "        \n",
    "        \n",
    "        def act_para(follow,model_loc,model,test_per,vali_per,batch,dims,outputs,\n",
    "                     dct_coe,data,b_vol,b_freq,silence,unk,t_sft,rate,dura,win_size,win_str):\n",
    "            toggle_train_save = widgets.ToggleButton(description='Save Test Setting', layout=Layout(width='30%', height='30px'), button_style='success')\n",
    "            toggle_run = widgets.ToggleButton(description='Start to Run', layout=Layout(width='30%', height='30px'), button_style='success')\n",
    "            out = widgets.Output(layout=Layout(border = '1px solid green'))\n",
    "            \n",
    "            if (follow):\n",
    "                self.form_box_train_para.layout.visibility = 'hidden'\n",
    "                self.form_box_data_para.layout.visibility = 'hidden'\n",
    "            else:\n",
    "                self.form_box_train_para.layout.visibility = 'visible'\n",
    "                self.form_box_data_para.layout.visibility = 'visible'\n",
    "            \n",
    "            def para_process(obj):\n",
    "                with out:\n",
    "                    if obj['new']:\n",
    "                        self.create_command([follow,model_loc,model,test_per,vali_per,batch,dims,outputs,\n",
    "                              dct_coe,data,b_vol,b_freq,silence,unk,t_sft,rate,dura,win_size,win_str])\n",
    "                        \n",
    "                        text0 = 'The training setting is finish and saved'\n",
    "                        html0= widgets.HTML(value = f\"<b><font color='lightblue'><font size=2>{text0}</b>\")\n",
    "                        display(html0)\n",
    "                        \n",
    "                    else:\n",
    "                        #print('re-start...')\n",
    "                        out.clear_output()\n",
    "                        \n",
    "            def run(obj):\n",
    "                with out:\n",
    "                    if obj['new']:\n",
    "                        self.run_test()\n",
    "                        print('Finish')\n",
    "                    else:\n",
    "                        #print('stop')\n",
    "                        out.clear_output()\n",
    "            \n",
    "            toggle_train_save.observe(para_process, 'value')\n",
    "            toggle_run.observe(run, 'value')\n",
    "            display(toggle_train_save, toggle_run)\n",
    "            display(out)\n",
    "                   \n",
    "        \n",
    "        out = widgets.interactive_output(act_para, {'follow': self.A_ch, 'model_loc': self.B_ch,\n",
    "                                                    'model': self.A_ta, 'test_per': self.B_ta, 'vali_per': self.C_ta, 'batch': self.G_ta, 'dims': self.H_ta,\n",
    "                                                    'outputs': self.I_ta, \n",
    "                                                    'dct_coe': self.A_da, 'data': self.B_da, 'b_vol': self.C_da, 'b_freq': self.D_da,\n",
    "                                                    'silence': self.E_da, 'unk': self.F_da, 't_sft': self.G_da, 'rate': self.H_da,\n",
    "                                                    'dura': self.I_da, 'win_size': self.J_da,  'win_str': self.K_da})\n",
    "        display(accordion, out)\n",
    "    \n",
    "    def run_test(self):   ###run the mainprogram\n",
    "        with open('test_cmd.txt','r') as f:  #save the complete command for train.py\n",
    "            train_cmd_line = f.read()\n",
    "        cmd_list = train_cmd_line.split()\n",
    "        \n",
    "        if(cmd_list != []):\n",
    "            print('read the test commands!')\n",
    "        else:\n",
    "            print('The test_cmd.txt is empty!')\n",
    "        \n",
    "        FLAGS, _ = parser.parse_known_args(args = cmd_list)\n",
    "        #FLAGS, _ = parser.parse_known_args(args = ['--model_architecture','dnn','--checkpoint',r'work\\DNN\\DNN3\\training\\best\\dnn_0.835_ckpt',\n",
    "        #'--model_size_info','128','128','128'])\n",
    "        #print(FLAGS)\n",
    "        test(FLAGS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3e4070-a542-410e-ad4c-5d6c59d85557",
   "metadata": {},
   "source": [
    "# Run Section\n",
    "---\n",
    "- The detail description of all the parameters is here [meaning](#id-PDD)\n",
    "- `Follow the train process setting`: Please directly use the train setting of the same model\n",
    "- `Model Location`: Please fill in the trained model location which is the `*_ckpt` file, for example: work/DNN/DNN2/training/dnn_0.826_ckpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3af42b7-fbe0-4771-b48b-9703f7e03fac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6f3d03751274646af8780bfdf0c1eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<b><font color='lightblue'><font size=4>Please Choose the parameters of the testing or using the d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.parentstyle > .p-Accordion-child > .p-Collapse-header{background-color:green}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec427f2b9b847788392a132b7f44ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Box(children=(Box(children=(Label(value='Follow the train process setting(recommend)'), Ch…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c61c6ee2ffd949a2a63fc49f61ae7d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "act = init_train_widgets()\n",
    "act.show_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de50131-315f-4cc9-aacc-256d9486d6cd",
   "metadata": {},
   "source": [
    "<a id=\"id-PDD\"></a>\n",
    "# Parameter Description\n",
    "---\n",
    "- This notebook is basing on https://github.com/ARM-software/ML-examples/tree/main/tflu-kws-cortex-m.\n",
    "- The Parameter Description is same as train, please check the `train.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a94cfeb-d597-4658-a085-0d27fb3683ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
