{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d35f286",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Import Section\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cf9265f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script is used for training a keyword spotting model using TensorFlow\n",
    "with ipywidgets UI.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "from collections import OrderedDict\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.python.profiler.model_analyzer import profile\n",
    "from tensorflow.python.profiler.option_builder import ProfileOptionBuilder\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout, Box, Dropdown, Label, IntSlider\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "from kws_python import data\n",
    "from kws_python import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc7f406",
   "metadata": {
    "id": "fcc7f406",
    "tags": []
   },
   "source": [
    "# Training Section\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4597593f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(flags, save_cmd_filename):\n",
    "    \"\"\"\n",
    "    Trains a TensorFlow model for keyword spotting.\n",
    "\n",
    "    Args:\n",
    "        flags: An object containing various training parameters such as:\n",
    "            - wanted_words: Comma-separated list of words to recognize.\n",
    "            - sample_rate: Audio sample rate.\n",
    "            - clip_duration_ms: Duration of each audio clip in milliseconds.\n",
    "            - window_size_ms: Duration of each spectrogram timeslice in milliseconds.\n",
    "            - window_stride_ms: How far to move in time between spectrogram timeslices.\n",
    "            - dct_coefficient_count: Number of bins to use for the MFCC fingerprint.\n",
    "            - model_architecture: Type of model architecture to use.\n",
    "            - model_size_info: List of integers defining the model layers.\n",
    "            - data_exist: Boolean indicating if data already exists.\n",
    "            - data_url: URL to download data from.\n",
    "            - data_dir: Directory to store data.\n",
    "            - silence_percentage: Percentage of training data that should be silence.\n",
    "            - unknown_percentage: Percentage of training data that should be unknown words.\n",
    "            - validation_percentage: Percentage of data to use for validation.\n",
    "            - testing_percentage: Percentage of data to use for testing.\n",
    "            - how_many_training_steps: Comma-separated list of number of training steps.\n",
    "            - learning_rate: Comma-separated list of learning rates.\n",
    "            - batch_size: Number of samples per batch.\n",
    "            - eval_step_interval: Number of steps between evaluations.\n",
    "            - train_dir: Directory to save training checkpoints and logs.\n",
    "            - summaries_dir: Directory to save TensorBoard summaries.\n",
    "            - save_cmd_filename: The filename to save the training command.\n",
    "\n",
    "    This function prepares the model settings, creates the model, processes the audio data, \n",
    "    sets up the learning rate schedule and optimizer, and trains the model. It also evaluates \n",
    "    the model on test data and saves the results, including the model's MACs and total parameters.\n",
    "    \"\"\"\n",
    "\n",
    "    model_settings = models.prepare_model_settings(\n",
    "        len(data.prepare_words_list(flags.wanted_words.split(\",\"))), flags.sample_rate, flags.clip_duration_ms, flags.window_size_ms, flags.window_stride_ms, flags.dct_coefficient_count\n",
    "    )\n",
    "\n",
    "    # Create the model.\n",
    "    model = models.create_model(model_settings, flags.model_architecture, flags.model_size_info, True)\n",
    "\n",
    "    audio_processor = data.AudioProcessor(\n",
    "        data_exist=flags.data_exist,\n",
    "        data_url=flags.data_url,\n",
    "        data_dir=flags.data_dir,\n",
    "        silence_percentage=flags.silence_percentage,\n",
    "        unknown_percentage=flags.unknown_percentage,\n",
    "        wanted_words=flags.wanted_words.split(\",\"),\n",
    "        validation_percentage=flags.validation_percentage,\n",
    "        testing_percentage=flags.testing_percentage,\n",
    "        model_settings=model_settings,\n",
    "    )\n",
    "\n",
    "    # We decay learning rate in a constant piecewise way to help learning.\n",
    "    training_steps_list = list(map(int, flags.how_many_training_steps.split(\",\")))\n",
    "    learning_rates_list = list(map(float, flags.learning_rate.split(\",\")))\n",
    "    lr_boundary_list = training_steps_list[:-1]  # Only need the values at which to change lr.\n",
    "    lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries=lr_boundary_list, values=learning_rates_list)\n",
    "\n",
    "    # Specify the optimizer configurations.\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    model.compile(optimizer=optimizer, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])\n",
    "\n",
    "    train_data = audio_processor.get_data(audio_processor.Modes.TRAINING, flags.background_frequency, flags.background_volume, int((flags.time_shift_ms * flags.sample_rate) / 1000))\n",
    "    train_data = train_data.repeat().batch(flags.batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    val_data = audio_processor.get_data(audio_processor.Modes.VALIDATION)\n",
    "    val_data = val_data.batch(flags.batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # We train for a max number of iterations so need to calculate how many 'epochs' this will be.\n",
    "    training_steps_max = np.sum(training_steps_list)\n",
    "    training_epoch_max = int(np.ceil(training_steps_max / flags.eval_step_interval))\n",
    "\n",
    "    # Callbacks.\n",
    "    train_dir = Path(flags.train_dir) / \"best\"\n",
    "    train_dir.mkdir(parents=True, exist_ok=True)\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath=(train_dir / (flags.model_architecture + \"_{val_accuracy:.3f}_ckpt\")), save_weights_only=True, monitor=\"val_accuracy\", mode=\"max\", save_best_only=True\n",
    "    )\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=flags.summaries_dir)\n",
    "\n",
    "    # Save the train model seeting\n",
    "    src = Path(os.getcwd()) / save_cmd_filename\n",
    "    dst = Path(os.getcwd()) / Path(flags.train_dir) / save_cmd_filename\n",
    "    shutil.copy(src, dst)\n",
    "\n",
    "    # Train the model.\n",
    "    model.fit(x=train_data, steps_per_epoch=flags.eval_step_interval, epochs=training_epoch_max, validation_data=val_data, callbacks=[model_checkpoint_callback, tensorboard_callback])\n",
    "\n",
    "    # Test and save the model.\n",
    "    test_data = audio_processor.get_data(audio_processor.Modes.TESTING)\n",
    "    test_data = test_data.batch(flags.batch_size)\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(x=test_data)\n",
    "    print(f\"Final test accuracy : {test_acc*100:.2f}% and test_loss : {test_loss:.4f}\")\n",
    "\n",
    "    # save result record\n",
    "    forward_pass = tf.function(model.call, input_signature=[tf.TensorSpec(shape=(1,) + model.input_shape[1:])])\n",
    "    graph_info = profile(forward_pass.get_concrete_function().graph, options=ProfileOptionBuilder.float_operation())\n",
    "    # The //2 is necessary since `profile` counts multiply and accumulate\n",
    "    # as two flops, here we report the total number of multiply accumulate ops\n",
    "    flops = graph_info.total_float_ops // 2\n",
    "    total_para = model.count_params()\n",
    "    print(f\"TensorFlow: {tf.__version__}\")\n",
    "    print(f\"The MACs of this model: {flops:,}\")\n",
    "    print(f\"The total parameters of this model: {total_para:,}\")\n",
    "\n",
    "    test_txt_path = os.path.join(os.getcwd(), flags.train_dir, \"result_record.txt\")\n",
    "    with open(test_txt_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"Test accuracy: {test_acc}\" + \"\\n\")\n",
    "        f.write(f\"MACs: {flops}\" + \"\\n\")\n",
    "        f.write(f\"Total Parameters: {total_para}\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7132a2fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Argument Setting\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8006c4e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--data_exist\", type=bool, default=True, help=\"True will skip download and tar.\")\n",
    "    parser.add_argument(\"--data_url\", type=str, default=\"http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz\", help=\"Location of speech training data archive on the web.\")\n",
    "    parser.add_argument(\n",
    "        \"--data_dir\",\n",
    "        type=str,\n",
    "        default=\"tmp/speech_dataset\",\n",
    "        help=\"\"\"\\\n",
    "        Where to download the speech training data to.\n",
    "        \"\"\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--background_volume\",\n",
    "        type=float,\n",
    "        default=0.1,\n",
    "        help=\"\"\"\\\n",
    "        How loud the background noise should be, between 0 and 1.\n",
    "        \"\"\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--background_frequency\",\n",
    "        type=float,\n",
    "        default=0.8,\n",
    "        help=\"\"\"\\\n",
    "        How many of the training samples have background noise mixed in.\n",
    "        \"\"\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--silence_percentage\",\n",
    "        type=float,\n",
    "        default=10.0,\n",
    "        help=\"\"\"\\\n",
    "        How much of the training data should be silence.\n",
    "        \"\"\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--unknown_percentage\",\n",
    "        type=float,\n",
    "        default=10.0,\n",
    "        help=\"\"\"\\\n",
    "        How much of the training data should be unknown words.\n",
    "        \"\"\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--time_shift_ms\",\n",
    "        type=float,\n",
    "        default=100.0,\n",
    "        help=\"\"\"\\\n",
    "        Range to randomly shift the training audio by in time.\n",
    "        \"\"\",\n",
    "    )\n",
    "    parser.add_argument(\"--testing_percentage\", type=int, default=10, help=\"What percentage of wavs to use as a test set.\")\n",
    "    parser.add_argument(\"--validation_percentage\", type=int, default=10, help=\"What percentage of wavs to use as a validation set.\")\n",
    "    parser.add_argument(\n",
    "        \"--sample_rate\",\n",
    "        type=int,\n",
    "        default=16000,\n",
    "        help=\"Expected sample rate of the wavs\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--clip_duration_ms\",\n",
    "        type=int,\n",
    "        default=1000,\n",
    "        help=\"Expected duration in milliseconds of the wavs\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--window_size_ms\",\n",
    "        type=float,\n",
    "        default=30.0,\n",
    "        help=\"How long each spectrogram timeslice is\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--window_stride_ms\",\n",
    "        type=float,\n",
    "        default=10.0,\n",
    "        help=\"How long each spectrogram timeslice is\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--dct_coefficient_count\",\n",
    "        type=int,\n",
    "        default=40,\n",
    "        help=\"How many bins to use for the MFCC fingerprint\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--how_many_training_steps\",\n",
    "        type=str,\n",
    "        # default='15,3',\n",
    "        default=\"15000,3000\",\n",
    "        help=\"How many training loops to run\",\n",
    "    )\n",
    "    parser.add_argument(\"--eval_step_interval\", type=int, default=400, help=\"How often to evaluate the training results.\")\n",
    "    parser.add_argument(\"--learning_rate\", type=str, default=\"0.001,0.0001\", help=\"How large a learning rate to use when training.\")\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        type=int,\n",
    "        default=100,\n",
    "        help=\"How many items to train with at once\",\n",
    "    )\n",
    "    parser.add_argument(\"--summaries_dir\", type=str, default=\"/tmp/retrain_logs\", help=\"Where to save summary logs for TensorBoard.\")\n",
    "    parser.add_argument(\n",
    "        \"--wanted_words\",\n",
    "        type=str,\n",
    "        default=\"yes,no\",\n",
    "        help=\"Words to use (others will be added to an unknown label)\",\n",
    "    )\n",
    "    parser.add_argument(\"--train_dir\", type=str, default=\"/tmp/speech_commands_train\", help=\"Directory to write event logs and checkpoint.\")\n",
    "    parser.add_argument(\"--model_architecture\", type=str, default=\"dnn\", help=\"What model architecture to use\")\n",
    "    parser.add_argument(\"--model_size_info\", type=int, nargs=\"+\", default=[128, 128, 128], help=\"Model dimensions - different for various models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a2b7b0-a778-43e4-a0fa-3c63831b1c59",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Widgets Control Section\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9608889-9419-4f76-89a8-b142f795d3fa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class InitTrainWidgets:\n",
    "    \"\"\"\n",
    "    A class to initialize and manage training and data parameter widgets for a machine learning model.\n",
    "    Methods\n",
    "    -------\n",
    "    folder_num_check(train_loc, dataset_list_check):\n",
    "        Checks if the number of files in each dataset folder is less than 15.\n",
    "    create_command(cm_list):\n",
    "        Creates a command dictionary from the provided list of parameters and saves it to a file.\n",
    "    show_main():\n",
    "        Displays the main interface with training and data parameter widgets and interactive controls.\n",
    "    run_test():\n",
    "        Reads the saved command file, parses the arguments, and runs the training process.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "\n",
    "        form_item_layout = Layout(\n",
    "            display=\"flex\",\n",
    "            flex_flow=\"row\",\n",
    "            justify_content=\"space-between\",\n",
    "        )\n",
    "\n",
    "        # train model parameters widgets\n",
    "        self.a_ta = Dropdown(options=[\"ds_cnn\", \"dnn\", \"cnn\", \"basic_lstm\"])\n",
    "        self.b_ta = widgets.BoundedIntText(value=10, min=0, max=50.0, step=1, disabled=False)\n",
    "        self.c_ta = widgets.BoundedIntText(value=10, min=0, max=50.0, step=1, disabled=False)\n",
    "        self.d_ta = widgets.Text(value=\"5000,10000,10000\", placeholder=\"Type something\", description=\"String:\", disabled=False)\n",
    "        self.e_ta = widgets.Text(value=\"0.0005,0.0001,0.00002\", placeholder=\"Type something\", description=\"String:\", disabled=False)\n",
    "        self.f_ta = widgets.IntSlider(value=400, min=100, max=1500, step=100)\n",
    "        self.g_ta = widgets.IntSlider(value=100, min=50, max=1000, step=50)\n",
    "        self.h_ta = widgets.Text(value=\"5 64 10 4 2 2 64 3 3 1 1 64 3 3 1 1 64 3 3 1 1 64 3 3 1 1\", placeholder=\"Type something\", description=\"Int:\", disabled=False)\n",
    "        self.i_ta = widgets.Textarea(value=\"yes,no,up,down,left,right,on,off,stop,go\", placeholder=\"Type something\", description=\"String:\", disabled=False)\n",
    "        self.j_ta = widgets.Text(value=\"work/DS_CNN/1/retrain_logs\", placeholder=\"Type something\", description=\"String:\", disabled=False)\n",
    "        self.k_ta = widgets.Text(value=\"work/DS_CNN/1/training\", placeholder=\"Type something\", description=\"String:\", disabled=False)\n",
    "\n",
    "        form_train_items = [\n",
    "            Box([Label(value=\"Model Architecture\"), self.a_ta], layout=form_item_layout),\n",
    "            Box([Label(value=\"Testing percentage\"), self.b_ta], layout=form_item_layout),\n",
    "            Box([Label(value=\"Validation percentage\"), self.c_ta], layout=form_item_layout),\n",
    "            Box([Label(value=\"Training Steps\"), self.d_ta], layout=form_item_layout),\n",
    "            Box([Label(value=\"Learning rates\"), self.e_ta], layout=form_item_layout),\n",
    "            Box([Label(value=\"Eval step interval\"), self.f_ta], layout=form_item_layout),\n",
    "            Box([Label(value=\"Batch size\"), self.g_ta], layout=form_item_layout),\n",
    "            Box([Label(value=\"Model size (dimension)\"), self.h_ta], layout=form_item_layout),\n",
    "            Box([Label(value=\"Wanted words\"), self.i_ta], layout=form_item_layout),\n",
    "            Box([Label(value=\"Summaries directory\"), self.j_ta], layout=form_item_layout),\n",
    "            Box([Label(value=\"Train directory\"), self.k_ta], layout=form_item_layout),\n",
    "        ]\n",
    "\n",
    "        self.form_box_train_para = Box(\n",
    "            form_train_items,\n",
    "            layout=Layout(\n",
    "                display=\"flex\",\n",
    "                flex_flow=\"column\",\n",
    "                border=\"solid 3px lightblue\",\n",
    "                align_items=\"stretch\",\n",
    "                width=\"50%\",\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # data parameters widgets\n",
    "        self.a_da = IntSlider(value=10, min=10, max=50)\n",
    "        self.b_da = widgets.Checkbox(value=True, disabled=False, indent=False)\n",
    "        self.c_da = widgets.FloatSlider(value=0.5, min=0.0, max=1.0)\n",
    "        self.d_da = widgets.FloatSlider(value=0.9, min=0.0, max=1.0)\n",
    "        self.e_da = widgets.FloatSlider(value=20.0, min=0.0, max=50.0)\n",
    "        self.f_da = widgets.FloatSlider(value=20.0, min=0.0, max=50.0)\n",
    "        self.g_da = widgets.FloatSlider(value=200.0, min=50.0, max=500.0, step=10.0)\n",
    "        self.h_da = widgets.IntSlider(value=16000, min=16000, max=32000, step=16000)\n",
    "        self.i_da = widgets.IntSlider(value=1000, min=800, max=3000, step=200)\n",
    "        self.j_da = widgets.IntSlider(value=40, min=10, max=100, step=10)\n",
    "        self.k_da = widgets.IntSlider(value=20, min=10, max=100, step=10)\n",
    "\n",
    "        form_data_items = [\n",
    "            Box([Label(value=\"DCT coefficient count\"), self.a_da], layout=form_item_layout),\n",
    "            Box([Label(value=\"Data exist\"), self.b_da], layout=form_item_layout),\n",
    "            Box([Label(value=\"Background volume\"), self.c_da], layout=form_item_layout),\n",
    "            Box([Label(value=\"Background frequency\"), self.d_da], layout=form_item_layout),\n",
    "            Box([Label(value=\"Silence percentage\"), self.e_da], layout=form_item_layout),\n",
    "            Box([Label(value=\"Unknown percentage\"), self.f_da], layout=form_item_layout),\n",
    "            Box([Label(value=\"Time shift (ms)\"), self.g_da], layout=form_item_layout),\n",
    "            Box([Label(value=\"Sample rate\"), self.h_da], layout=form_item_layout),\n",
    "            Box([Label(value=\"Clip duration (ms)\"), self.i_da], layout=form_item_layout),\n",
    "            Box([Label(value=\"Window size (ms)\"), self.j_da], layout=form_item_layout),\n",
    "            Box([Label(value=\"Window stride (ms)\"), self.k_da], layout=form_item_layout),\n",
    "        ]\n",
    "\n",
    "        self.form_box_data_para = Box(\n",
    "            form_data_items,\n",
    "            layout=Layout(\n",
    "                display=\"flex\",\n",
    "                flex_flow=\"column\",\n",
    "                border=\"solid 3px lightblue\",\n",
    "                align_items=\"stretch\",\n",
    "                width=\"50%\",\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # button widgets\n",
    "        self.a_bu = widgets.Button(description=\"Save Train Setting\", layout=Layout(width=\"30%\", height=\"30px\"), button_style=\"success\")\n",
    "        self.b_bu = widgets.Button(description=\"Start to Run\", layout=Layout(width=\"30%\", height=\"30px\"), button_style=\"success\")\n",
    "\n",
    "        form_button_items = [self.a_bu, self.b_bu]\n",
    "\n",
    "        self.form_button = Box(\n",
    "            form_button_items,\n",
    "            layout=Layout(\n",
    "                display=\"flex\",\n",
    "                flex_flow=\"column\",\n",
    "                # border='solid 3px lightblue',\n",
    "                align_items=\"stretch\",\n",
    "                width=\"50%\",\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def folder_num_check(self, train_loc, dataset_list_check):\n",
    "        \"\"\"\n",
    "        Checks the number of files in each folder within a given directory.\n",
    "        Args:\n",
    "            train_loc (str): The path to the main directory containing subfolders.\n",
    "            dataset_list_check (list): A list of subfolder names to check within the main directory.\n",
    "        Returns:\n",
    "            int: Returns 1 if any subfolder contains fewer than 15 files, otherwise returns 0.\n",
    "        \"\"\"\n",
    "        for fld_name in dataset_list_check:\n",
    "            check_fld = os.path.join(train_loc, fld_name)\n",
    "            length = len([entry for entry in os.listdir(check_fld) if os.path.isfile(os.path.join(check_fld, entry))])\n",
    "            if 15 > length:  # need < 15\n",
    "                return 1\n",
    "        return 0\n",
    "\n",
    "    def create_command(self, cm_list):\n",
    "        \"\"\"\n",
    "        Creates a command dictionary from a list of command-line arguments and writes it to a file.\n",
    "        Args:\n",
    "            cm_list (list): A list of command-line argument values.\n",
    "        Returns:\n",
    "            int: Always returns 0.\n",
    "        \"\"\"\n",
    "        argument_list = [\n",
    "            \"--model_architecture\",\n",
    "            \"--testing_percentage\",\n",
    "            \"--validation_percentage\",\n",
    "            \"--how_many_training_steps\",\n",
    "            \"--learning_rate\",\n",
    "            \"--eval_step_interval\",\n",
    "            \"-batch_size\",\n",
    "            \"--model_size_info\",\n",
    "            \"--wanted_words\",\n",
    "            \"--summaries_dir\",\n",
    "            \"--train_dir\",\n",
    "            \"--dct_coefficient_count\",\n",
    "            \"--data_exist\",\n",
    "            \"--background_volume\",\n",
    "            \"--background_frequency\",\n",
    "            \"--silence_percentage\",\n",
    "            \"--unknown_percentage\",\n",
    "            \"--time_shift_ms\",\n",
    "            \"--sample_rate\",\n",
    "            \"--clip_duration_ms\",\n",
    "            \"--window_size_ms\",\n",
    "            \"--window_stride_ms\",\n",
    "        ]\n",
    "        cm_dict = OrderedDict()\n",
    "\n",
    "        for idx, val in enumerate(cm_list):\n",
    "            if argument_list[idx] == \"--model_size_info\":  # transfer from single string to list format\n",
    "                cm_dict[argument_list[idx]] = val.split(\",\")\n",
    "            else:\n",
    "                cm_dict[argument_list[idx]] = val\n",
    "        print(cm_dict)\n",
    "\n",
    "        with open(\"train_cmd.txt\", \"w\", encoding=\"utf-8\") as f:  # save the complete command for train.py\n",
    "            for key, value in cm_dict.items():\n",
    "\n",
    "                if isinstance(value, list): \n",
    "                    f.write(f\"{key} \")\n",
    "                    for _, val in enumerate(value):\n",
    "                        f.write(f\"{val} \")\n",
    "                else:\n",
    "                    f.write(f\"{key} {value} \")\n",
    "\n",
    "        return 0\n",
    "\n",
    "    def show_main(self):\n",
    "        \"\"\"\n",
    "        Displays the main interface for setting training parameters and running the training process.\n",
    "        This method creates an interactive UI using Jupyter widgets to allow users to configure training\n",
    "        parameters or use default settings. It includes an accordion with sections for \"Train Setting\" \n",
    "        and \"Data Setting\". Users can save the training settings or start the training process.\n",
    "        \"\"\"\n",
    "\n",
    "        intro_text = \"Please Choose the parameters of the training or using the default\"\n",
    "        html_widget = widgets.HTML(value=f\"<b><font color='lightgreen'><font size=6>{intro_text}</b>\")\n",
    "        display(html_widget)\n",
    "\n",
    "        # Create an accordion and put the 2 boxes\n",
    "        accordion = widgets.Accordion(children=[self.form_box_train_para, self.form_box_data_para]).add_class(\"parentstyle\")\n",
    "        # Add a custom style tag to the notebook, you can use dev tool to inspect the class names\n",
    "        display(HTML(\"<style>.parentstyle > .p-Accordion-child > .p-Collapse-header{background-color:green}</style>\"))\n",
    "        accordion.set_title(0, \"Train Setting\")\n",
    "        accordion.set_title(1, \"Data Setting\")\n",
    "\n",
    "        output_widgets = widgets.Output(layout=Layout(border=\"1px solid green\"))\n",
    "\n",
    "        def act_para(*, model, test_per, vali_per, steps, lr, step_inter, batch, dims, outputs, sum_dir, train_dir, dct_coe, data_b_da, b_vol, b_freq, silence, unk, t_sft, rate, dura, win_size, win_str):\n",
    "            #toggle_train_save = widgets.ToggleButton(description=\"Save Train Setting\", layout=Layout(width=\"30%\", height=\"30px\"), button_style=\"success\")\n",
    "            #toggle_run = widgets.ToggleButton(description=\"Start to Run\", layout=Layout(width=\"30%\", height=\"30px\"), button_style=\"success\")\n",
    "\n",
    "            #out = widgets.Output(layout=Layout(border=\"1px solid green\"))\n",
    "\n",
    "            # If any value is changed, clear the widgets\n",
    "            with output_widgets:\n",
    "                output_widgets.clear_output()\n",
    "\n",
    "            #def para_process(obj):\n",
    "            #    with out:\n",
    "            #        clear_output()\n",
    "            #        if obj[\"new\"]:\n",
    "            #            self.create_command(\n",
    "            #                [\n",
    "            #                    model,\n",
    "            #                    test_per,\n",
    "            #                    vali_per,\n",
    "            #                    steps,\n",
    "            #                    lr,\n",
    "            #                    step_inter,\n",
    "            #                    batch,\n",
    "            #                    dims,\n",
    "            #                    outputs,\n",
    "            #                    sum_dir,\n",
    "            #                    train_dir,\n",
    "            #                    dct_coe,\n",
    "            #                    data_b_da,\n",
    "            #                    b_vol,\n",
    "            #                    b_freq,\n",
    "            #                    silence,\n",
    "            #                    unk,\n",
    "            #                    t_sft,\n",
    "            #                    rate,\n",
    "            #                    dura,\n",
    "            #                    win_size,\n",
    "            #                    win_str,\n",
    "            #                ]\n",
    "            #            )\n",
    "#\n",
    "            #            text0 = \"The training setting is finish and saved\"\n",
    "            #            html0 = widgets.HTML(value=f\"<b><font color='lightblue'><font size=2>{text0}</b>\")\n",
    "            #            display(html0)\n",
    "#\n",
    "            #        else:\n",
    "            #            print(\"re-start...\")\n",
    "\n",
    "            #def run(obj):\n",
    "            #    with out:\n",
    "            #        clear_output()\n",
    "            #        if obj[\"new\"]:\n",
    "            #            self.run_test()\n",
    "            #        else:\n",
    "            #            print(\"stop\")\n",
    "\n",
    "            #toggle_train_save.observe(para_process, \"value\")\n",
    "            #toggle_run.observe(run, \"value\")\n",
    "            #display(toggle_train_save, toggle_run)\n",
    "            #display(out)\n",
    "\n",
    "\n",
    "        out_inter = widgets.interactive_output(\n",
    "            act_para,\n",
    "            {\n",
    "                \"model\": self.a_ta,\n",
    "                \"test_per\": self.b_ta,\n",
    "                \"vali_per\": self.c_ta,\n",
    "                \"steps\": self.d_ta,\n",
    "                \"lr\": self.e_ta,\n",
    "                \"step_inter\": self.f_ta,\n",
    "                \"batch\": self.g_ta,\n",
    "                \"dims\": self.h_ta,\n",
    "                \"outputs\": self.i_ta,\n",
    "                \"sum_dir\": self.j_ta,\n",
    "                \"train_dir\": self.k_ta,\n",
    "                \"dct_coe\": self.a_da,\n",
    "                \"data_b_da\": self.b_da,\n",
    "                \"b_vol\": self.c_da,\n",
    "                \"b_freq\": self.d_da,\n",
    "                \"silence\": self.e_da,\n",
    "                \"unk\": self.f_da,\n",
    "                \"t_sft\": self.g_da,\n",
    "                \"rate\": self.h_da,\n",
    "                \"dura\": self.i_da,\n",
    "                \"win_size\": self.j_da,\n",
    "                \"win_str\": self.k_da,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        display(accordion, self.form_button, out_inter)\n",
    "        display(output_widgets)\n",
    "\n",
    "        def on_button_clicked_save_train_set(b):\n",
    "            with output_widgets:\n",
    "                clear_output()\n",
    "                self.create_command(\n",
    "                    [\n",
    "                        self.a_ta.value,\n",
    "                        self.b_ta.value,\n",
    "                        self.c_ta.value,\n",
    "                        self.d_ta.value,\n",
    "                        self.e_ta.value,\n",
    "                        self.f_ta.value,\n",
    "                        self.g_ta.value,\n",
    "                        self.h_ta.value,\n",
    "                        self.i_ta.value,\n",
    "                        self.j_ta.value,\n",
    "                        self.k_ta.value,\n",
    "                        self.a_da.value,\n",
    "                        self.b_da.value,\n",
    "                        self.c_da.value,\n",
    "                        self.d_da.value,\n",
    "                        self.e_da.value,\n",
    "                        self.f_da.value,\n",
    "                        self.g_da.value,\n",
    "                        self.h_da.value,\n",
    "                        self.i_da.value,\n",
    "                        self.j_da.value,\n",
    "                        self.k_da.value,\n",
    "                    ]\n",
    "                )\n",
    "                text0 = \"The training setting is finish and saved\"\n",
    "                html0 = widgets.HTML(value=f\"<b><font color='lightblue'><font size=2>{text0}</b>\")\n",
    "                display(html0)\n",
    "        self.a_bu.on_click(on_button_clicked_save_train_set)\n",
    "\n",
    "        def on_button_clicked_train(b):\n",
    "            with output_widgets:\n",
    "                clear_output()\n",
    "                self.run_test()\n",
    "    \n",
    "        self.b_bu.on_click(on_button_clicked_train)    \n",
    "\n",
    "    def run_test(self):  # run the mainprogram\n",
    "        \"\"\"\n",
    "        Executes the main program for training.\n",
    "        This method reads a command from a file, processes it, and runs the training\n",
    "        program based on the provided command. It also checks the dataset's validity\n",
    "        before proceeding with the training.\n",
    "        \"\"\"\n",
    "        save_cmd_filename = \"train_cmd.txt\"\n",
    "        with open(save_cmd_filename, \"r\", encoding=\"utf-8\") as f:  # save the complete command for train.py\n",
    "            train_cmd_line = f.read()\n",
    "        cmd_list = train_cmd_line.split()\n",
    "        print(cmd_list)\n",
    "\n",
    "        dataset_list_check = []\n",
    "\n",
    "        for idx, val in enumerate(cmd_list):\n",
    "            if val == \"False\":\n",
    "                print(\"change to bool\")\n",
    "                cmd_list[idx] = False\n",
    "            if val == \"--wanted_words\":  # get the dataset's name\n",
    "                dataset_list_check = cmd_list[idx + 1].split(\",\")\n",
    "\n",
    "        if cmd_list != []:\n",
    "            print(\"read the train commands!\")\n",
    "        else:\n",
    "            print(\"The train_cmd.txt is empty!\")\n",
    "\n",
    "        flags, _ = parser.parse_known_args(args=cmd_list)\n",
    "\n",
    "        dataset_loc_for_check = os.path.join(os.getcwd(), \"tmp\", \"speech_dataset\")\n",
    "\n",
    "        if not self.b_da.value:\n",
    "            train(flags, save_cmd_filename)\n",
    "            print(\"Finish\")\n",
    "        elif self.folder_num_check(dataset_loc_for_check, dataset_list_check):  # if any files < 15, don't run training\n",
    "            print(\"The data is not enough, please > 15 files in each label folder.\")\n",
    "            print(f\"The dataset path: {dataset_loc_for_check}\")\n",
    "        else:\n",
    "            train(flags, save_cmd_filename)\n",
    "            print(\"Finish\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cea60e3-7da5-49a7-addb-459ae9b6063a",
   "metadata": {},
   "source": [
    "# Run Section\n",
    "---\n",
    "- The detail description of all the parameters is here [meaning](#id-PD)\n",
    "- Please download the google train data at first time ==> click`Data Setting` tab, and unclick the `Data exist`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e76ba7b-090f-4409-8c3a-b53af9400689",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac6613f6d2c24d688001c00b0811a425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<b><font color='lightgreen'><font size=6>Please Choose the parameters of the training or using the…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.parentstyle > .p-Accordion-child > .p-Collapse-header{background-color:green}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f3a5da417304d078f80eb5636ed7f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Box(children=(Box(children=(Label(value='Model Architecture'), Dropdown(options=('ds_cnn',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef00efbaf8c4788a39eb97dc1f776d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Button(button_style='success', description='Save Train Setting', layout=Layout(height='30px', wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae0eaf72442b4c77b382f3e9a8d675ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6983a3c78e024d77be46c5e9bf22f1a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid green', border_left='1px solid green', border_right='1px solid g…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "act = InitTrainWidgets()\n",
    "act.show_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0234c522-6760-4bec-be5d-8d2edb26e45a",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id=\"id-PD\"></a>\n",
    "# Parameter Description\n",
    "---\n",
    "- This notebook is basing on https://github.com/ARM-software/ML-examples/tree/main/tflu-kws-cortex-m.\n",
    "\n",
    "## Train Setting\n",
    "- `Model Architecture`: What model architecture to use.\n",
    "- `Testing percentage`: What percentage of wavs as a test set.\n",
    "- `Validation percentage`: What percentage of wavs as a validation set.\n",
    "- `Training steps`: How many training loops to run. It matches with the learning rates.\n",
    "- `Learning rates`: How large a learning rate to use when training. It matches with the training steps.\n",
    "- `Eval step interval`: How often to evaluate the training results.\n",
    "- `Batch size`: How many items to train with at once.\n",
    "- `Model size (dimension)`: Model dimensions - different for various models. For more detail, please check the `train_commands.txt`.\n",
    "- `Wanted words`: Words to use (others will be added to an unknown label).\n",
    "- `Summaries directory`: Where to save summary logs for TensorBoard.\n",
    "- `Train directory`: Directory to write event logs and checkpoint(The trained model and weights).\n",
    "\n",
    "## Data Setting\n",
    "- `DCT coefficient count`: How many bins to use for the MFCC fingerprint\n",
    "- `Data exist`: True will skip download and tar the default tensorflow's speech dataset. (Notice)When you first play this notebook, please unclick it for downlowing the train dataset at first time.\n",
    "- `Background volume`: How loud the background noise should be, between 0 and 1.\n",
    "- `Background frequency`: How many of the training samples have background noise mixed in.\n",
    "- `Silence percentage`: How much of the training data should be silence.\n",
    "- `Unknown percentage`: How much of the training data should be unknown words.\n",
    "- `Time shift (ms)`: Range to randomly shift the training audio by in time.\n",
    "- `Sample rate`: Expected sample rate of the wavs.\n",
    "- `Clip duration (ms)`: Expected duration in milliseconds of the wavs.\n",
    "- `Window size (ms)`: How long each spectrogram timeslice is.\n",
    "- `Window stride (ms)`: Window stride in samples for calculating spectrogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89024e38-250c-44a3-9a23-db364332be82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NuEdgeWise_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
